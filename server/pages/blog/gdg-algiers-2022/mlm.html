<!DOCTYPE html><html lang="en" class="scroll-smooth"><head><link rel="apple-touch-icon" sizes="76x76" href="/static/favicons/apple-touch-icon.png?v=2"/><link rel="icon" type="image/png" sizes="32x32" href="/static/favicons/favicon-32x32.png?v=2"/><link rel="icon" type="image/png" sizes="16x16" href="/static/favicons/favicon-16x16.png?v=2"/><link rel="manifest" href="/static/favicons/site.webmanifest?v=2"/><link rel="mask-icon" href="/static/favicons/safari-pinned-tab.svg?v=2" color="#5bbad5"/><meta name="msapplication-TileColor" content="#da532c"/><meta name="theme-color" content="#ffffff"/><link rel="alternate" type="application/rss+xml" href="/feed.xml"/><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous"/><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.11/dist/katex.min.css" integrity="sha384-Um5gpz1odJg5Z4HAmzPtgZKdTBHZdw8S29IecapCSB31ligYPhHQZMIlWLYQGVoc" crossorigin="anonymous"/><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin /><meta charSet="utf-8"/><script>!function(){try {var d=document.documentElement.classList;d.remove('light','dark');var e=localStorage.getItem('theme');d.add('dark');if("system"===e||(!e&&false)){var t="(prefers-color-scheme: dark)",m=window.matchMedia(t);m.media!==t||m.matches?d.add('dark'):d.add('light')}else if(e) d.add(e)}catch(e){}}()</script><meta content="width=device-width, initial-scale=1" name="viewport"/><title>GDG Algiers CTF 2022 – MLM</title><meta name="robots" content="follow, index"/><meta name="description" content="Analyze pcapng for BERT layer data, then predict flag with Masked Language Modelling."/><meta property="og:url" content="https://sekai.team/blog/gdg-algiers-2022/mlm/"/><meta property="og:type" content="article"/><meta property="og:site_name" content="Project SEKAI"/><meta property="og:description" content="Analyze pcapng for BERT layer data, then predict flag with Masked Language Modelling."/><meta property="og:title" content="GDG Algiers CTF 2022 – MLM"/><meta property="og:image" content="https://og-vercel-ruby.vercel.app/api/sekai?title=GDG+Algiers+CTF+2022+%E2%80%93+MLM&amp;desc=Analyze+pcapng+for+BERT+layer+data%2C+then+predict+flag+with+Masked+Language+Modelling.&amp;authors=sahuang"/><meta name="twitter:card" content="summary_large_image"/><meta name="twitter:site" content="https://twitter.com/ProjectSEKAIctf"/><meta name="twitter:title" content="GDG Algiers CTF 2022 – MLM"/><meta name="twitter:description" content="Analyze pcapng for BERT layer data, then predict flag with Masked Language Modelling."/><meta name="twitter:image" content="https://og-vercel-ruby.vercel.app/api/sekai?title=GDG+Algiers+CTF+2022+%E2%80%93+MLM&amp;desc=Analyze+pcapng+for+BERT+layer+data%2C+then+predict+flag+with+Masked+Language+Modelling.&amp;authors=sahuang"/><meta property="article:published_time" content="2022-10-09T00:00:00.000Z"/><link rel="canonical" href="https://sahuang.github.io/writeups/gdg-algiers-ctf-2022"/><link rel="canonical" href="https://sekai.team/blog/gdg-algiers-2022/mlm/"/><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "Article",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://sekai.team/blog/gdg-algiers-2022/mlm"
  },
  "headline": "GDG Algiers CTF 2022 – MLM",
  "image": [
    {
      "@type": "ImageObject",
      "url": "https://og-vercel-ruby.vercel.app/api/sekai?title=GDG+Algiers+CTF+2022+%E2%80%93+MLM&desc=Analyze+pcapng+for+BERT+layer+data%2C+then+predict+flag+with+Masked+Language+Modelling.&authors=sahuang"
    }
  ],
  "datePublished": "2022-10-09T00:00:00.000Z",
  "dateModified": "2022-10-09T00:00:00.000Z",
  "author": [
    {
      "@type": "Person",
      "name": "sahuang"
    }
  ],
  "publisher": {
    "@type": "Organization",
    "name": "Project SEKAI",
    "logo": {
      "@type": "ImageObject",
      "url": "https://sekai.team/static/images/fullLogo.svg"
    }
  },
  "description": "Analyze pcapng for BERT layer data, then predict flag with Masked Language Modelling."
}</script><meta name="next-head-count" content="21"/><link rel="preload" href="/_next/static/css/206f24680f6266ec.css" as="style"/><link rel="stylesheet" href="/_next/static/css/206f24680f6266ec.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-5cd94c89d3acac5f.js"></script><script src="/_next/static/chunks/webpack-09a75c9ee2bd415e.js" defer=""></script><script src="/_next/static/chunks/main-b8c3e234d7065a2c.js" defer=""></script><script src="/_next/static/chunks/pages/_app-b8cbc7cb85baf88e.js" defer=""></script><script src="/_next/static/chunks/framework-327e104994690a53.js" defer=""></script><script src="/_next/static/chunks/29107295-a2d0c8e72019a3ed.js" defer=""></script><script src="/_next/static/chunks/545-f1dc6b53ce85b08b.js" defer=""></script><script src="/_next/static/chunks/930-1296a6163e1e3cc6.js" defer=""></script><script src="/_next/static/chunks/pages/blog/%5B...slug%5D-9a47024c9df525b8.js" defer=""></script><script src="/_next/static/zs4rZRwOZcgSj8qsc8Zvy/_buildManifest.js" defer=""></script><script src="/_next/static/zs4rZRwOZcgSj8qsc8Zvy/_ssgManifest.js" defer=""></script><script src="/_next/static/zs4rZRwOZcgSj8qsc8Zvy/_middlewareManifest.js" defer=""></script><style data-href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700&display=swap">@font-face{font-family:'Inter';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/l/font?kit=UcCO3FwrK3iLTeHuS_fvQtMwCp50KnMw2boKoduKmMEVuLyfMZs&skey=c491285d6722e4fa&v=v13) format('woff')}@font-face{font-family:'Inter';font-style:normal;font-weight:600;font-display:swap;src:url(https://fonts.gstatic.com/l/font?kit=UcCO3FwrK3iLTeHuS_fvQtMwCp50KnMw2boKoduKmMEVuGKYMZs&skey=c491285d6722e4fa&v=v13) format('woff')}@font-face{font-family:'Inter';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/l/font?kit=UcCO3FwrK3iLTeHuS_fvQtMwCp50KnMw2boKoduKmMEVuFuYMZs&skey=c491285d6722e4fa&v=v13) format('woff')}@font-face{font-family:'Inter';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v13/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa2JL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0460-052F,U+1C80-1C88,U+20B4,U+2DE0-2DFF,U+A640-A69F,U+FE2E-FE2F}@font-face{font-family:'Inter';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v13/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa0ZL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0301,U+0400-045F,U+0490-0491,U+04B0-04B1,U+2116}@font-face{font-family:'Inter';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v13/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa2ZL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+1F00-1FFF}@font-face{font-family:'Inter';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v13/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa1pL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0370-0377,U+037A-037F,U+0384-038A,U+038C,U+038E-03A1,U+03A3-03FF}@font-face{font-family:'Inter';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v13/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa2pL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0102-0103,U+0110-0111,U+0128-0129,U+0168-0169,U+01A0-01A1,U+01AF-01B0,U+0300-0301,U+0303-0304,U+0308-0309,U+0323,U+0329,U+1EA0-1EF9,U+20AB}@font-face{font-family:'Inter';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v13/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa25L7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0100-02AF,U+0304,U+0308,U+0329,U+1E00-1E9F,U+1EF2-1EFF,U+2020,U+20A0-20AB,U+20AD-20C0,U+2113,U+2C60-2C7F,U+A720-A7FF}@font-face{font-family:'Inter';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v13/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa1ZL7W0Q5nw.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+0304,U+0308,U+0329,U+2000-206F,U+2074,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}@font-face{font-family:'Inter';font-style:normal;font-weight:600;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v13/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa2JL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0460-052F,U+1C80-1C88,U+20B4,U+2DE0-2DFF,U+A640-A69F,U+FE2E-FE2F}@font-face{font-family:'Inter';font-style:normal;font-weight:600;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v13/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa0ZL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0301,U+0400-045F,U+0490-0491,U+04B0-04B1,U+2116}@font-face{font-family:'Inter';font-style:normal;font-weight:600;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v13/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa2ZL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+1F00-1FFF}@font-face{font-family:'Inter';font-style:normal;font-weight:600;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v13/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa1pL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0370-0377,U+037A-037F,U+0384-038A,U+038C,U+038E-03A1,U+03A3-03FF}@font-face{font-family:'Inter';font-style:normal;font-weight:600;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v13/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa2pL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0102-0103,U+0110-0111,U+0128-0129,U+0168-0169,U+01A0-01A1,U+01AF-01B0,U+0300-0301,U+0303-0304,U+0308-0309,U+0323,U+0329,U+1EA0-1EF9,U+20AB}@font-face{font-family:'Inter';font-style:normal;font-weight:600;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v13/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa25L7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0100-02AF,U+0304,U+0308,U+0329,U+1E00-1E9F,U+1EF2-1EFF,U+2020,U+20A0-20AB,U+20AD-20C0,U+2113,U+2C60-2C7F,U+A720-A7FF}@font-face{font-family:'Inter';font-style:normal;font-weight:600;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v13/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa1ZL7W0Q5nw.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+0304,U+0308,U+0329,U+2000-206F,U+2074,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}@font-face{font-family:'Inter';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v13/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa2JL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0460-052F,U+1C80-1C88,U+20B4,U+2DE0-2DFF,U+A640-A69F,U+FE2E-FE2F}@font-face{font-family:'Inter';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v13/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa0ZL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0301,U+0400-045F,U+0490-0491,U+04B0-04B1,U+2116}@font-face{font-family:'Inter';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v13/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa2ZL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+1F00-1FFF}@font-face{font-family:'Inter';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v13/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa1pL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0370-0377,U+037A-037F,U+0384-038A,U+038C,U+038E-03A1,U+03A3-03FF}@font-face{font-family:'Inter';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v13/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa2pL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0102-0103,U+0110-0111,U+0128-0129,U+0168-0169,U+01A0-01A1,U+01AF-01B0,U+0300-0301,U+0303-0304,U+0308-0309,U+0323,U+0329,U+1EA0-1EF9,U+20AB}@font-face{font-family:'Inter';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v13/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa25L7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0100-02AF,U+0304,U+0308,U+0329,U+1E00-1E9F,U+1EF2-1EFF,U+2020,U+20A0-20AB,U+20AD-20C0,U+2113,U+2C60-2C7F,U+A720-A7FF}@font-face{font-family:'Inter';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v13/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa1ZL7W0Q5nw.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+0304,U+0308,U+0329,U+2000-206F,U+2074,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}</style></head><body class="antialiased text-black bg-white dark:bg-gray-900 dark:text-white"><div id="__next" data-reactroot=""><div class="max-w-3xl px-4 mx-auto sm:px-6 xl:max-w-5xl xl:px-0"><div class="flex flex-col justify-between h-screen"><header class="flex items-center justify-between py-10"><div><a aria-label="Visit home page" href="/"><div class="flex items-center justify-between"><div class="mr-3"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 468.7 215.63" height="80" width="auto"><defs><linearGradient id="fullLogo_svg__linear-gradient" x1="-7051.74" y1="5608.42" x2="-7051.74" y2="5392.1" gradientTransform="matrix(1 0 .15 -.99 6503.98 5547.9)" gradientUnits="userSpaceOnUse"><stop offset="0" stop-color="#00e5ea"></stop><stop offset="1" stop-color="#00b5cc"></stop></linearGradient><linearGradient id="fullLogo_svg__linear-gradient-2" x1="1498.32" y1="4428.84" x2="1497.92" y2="4311.82" gradientTransform="matrix(1 0 0 -1 -1107.01 4435.41)" xlink:href="#fullLogo_svg__linear-gradient"></linearGradient><linearGradient id="fullLogo_svg__linear-gradient-3" x1="320.76" y1="14.17" x2="320.76" y2="47.97" gradientUnits="userSpaceOnUse"><stop offset="0" stop-color="#0069a5"></stop><stop offset="1" stop-color="#003d6b"></stop></linearGradient><style>.fullLogo_svg__cls-1{fill:#fff}</style></defs><g id="fullLogo_svg__Project_SEKAI_Wide_White" data-name="Project SEKAI Wide White"><path class="fullLogo_svg__cls-1" d="M107 117.14v-4c11.93 0 22.15-8.62 23.76-20l12.91-91.63h4.06l-13 92.14c-1.92 13.4-13.84 23.49-27.73 23.49Z"></path><path class="fullLogo_svg__cls-1" d="M97.43 98.3a16 16 0 0 1-16.26-18.72l8.68-61.42A21.78 21.78 0 0 1 110.77 0a16.34 16.34 0 0 1 12.57 5.5A16.36 16.36 0 0 1 127 18.72l-8.69 61.42c-1.39 10.01-10.77 18.16-20.88 18.16ZM110.77 4a17.63 17.63 0 0 0-17 14.72l-8.64 61.42a12 12 0 0 0 12.3 14.16 17.65 17.65 0 0 0 16.95-14.72l8.69-61.42a12.41 12.41 0 0 0-2.75-10A12.4 12.4 0 0 0 110.77 4ZM186.94 5.42l.56-3.91H162.99l-13.5 95.44H174l.57-4h-20.46l5.85-41.36h20.46l.56-4h-20.45l5.96-42.17h20.45zM266.73 1.51h-31.01l-.55 3.91h14.2l-12.95 91.53h4.06l12.93-91.53h12.77l.55-3.91zM212.61 1.51a15.86 15.86 0 0 0-15.24 13.24l-9.86 69.48a11.69 11.69 0 0 0 2.76 9.34 12.57 12.57 0 0 0 9.18 4.43h.2c6.38 0 11.65-5.57 15.15-9.28L211.9 86c-3.06 3.23-7.67 8.11-12.38 8a8.54 8.54 0 0 1-6.21-3 7.73 7.73 0 0 1-1.84-6.18l9.86-69.48a11.83 11.83 0 0 1 11.28-9.9h13.91l.55-3.91ZM37.08 5.58a12 12 0 0 0-9.26-4.06H13.5L0 97h4.06l6.41-45.37h10.84a15.87 15.87 0 0 0 15.24-13.29l3.25-23a12 12 0 0 0-2.72-9.76Zm-1.24 9.17-3.26 23a11.74 11.74 0 0 1-11.27 9.8H11l6-42.13h10.85a7.94 7.94 0 0 1 8 9.33ZM75.09 5.58a12 12 0 0 0-9.26-4.06h-14.3L38 97h4l6.5-45.42h10L65 96.2h4l-6.6-45a16 16 0 0 0 12.16-12.86l3.25-23a12 12 0 0 0-2.72-9.76Zm-1.24 9.17-3.25 23a11.76 11.76 0 0 1-11.28 9.8H49.07L55 5.42h10.86a7.94 7.94 0 0 1 8 9.33ZM223.75 215.47h-4.06l13.5-95.43h4.05l-13.49 95.43zM65.83 215.63a14.49 14.49 0 0 1-11-4.65 11.3 11.3 0 0 1-2.68-9.15l1.31-8.59 4.4-2.34-1.76 11.52a7.24 7.24 0 0 0 1.75 5.93 10.47 10.47 0 0 0 8 3.28c6.42 0 12.26-4.39 13-9.8l5.42-38.33-28.77 15.27 6.37-46c1-7.3 8.65-13.24 17-13.24a14.52 14.52 0 0 1 11 4.65 11.36 11.36 0 0 1 2.68 9.14l-1.2 8.68-4.35 2.34 1.64-11.6a7.29 7.29 0 0 0-1.74-6 10.5 10.5 0 0 0-8-3.28c-6.42 0-12.26 4.39-13 9.79l-5.29 38.27 28.8-15.28-6.52 46.1c-1.11 7.35-8.73 13.29-17.06 13.29ZM174.15 120.04h-4.51l-26.9 51.72 7.31-51.72H146l-13.5 95.43h4.05l4.5-31.8 10.61-20.4 12.61 52.2h4.11l-13.91-57.6 19.68-37.83zM205 215.47h4l-2.29-94.87v-.56h-4l-29.31 95.43h4.18l9.82-32h16.83Zm-16.37-36L203 132.68l1.13 46.81ZM132.58 123.94l.56-3.91h-24.52l-13.49 95.44h24.51l.56-4H99.75l5.85-41.36h20.45l.57-4h-20.46l5.97-42.17h20.45z"></path><path style="fill:url(#fullLogo_svg__linear-gradient)" d="M279.69 1.51h8.87l-32.09 213.93h-8.87L279.69 1.51z"></path><path d="M393.81 14.88C396 .34 331.4 1.5 296.53 1.5L283.6 87.67c33.36-1.94 99.5-2 97.21 13.27-1.14 7.58-5.53 7.29-6.1 11.08-1.52 10.14 70.94 5.62 81.15 4.52L434 73.6l34.7-43.29c-17.47 1.81-82.47 4.94-81.11-4.15.73-4.87 5.41-5.56 6.22-11.28Z" style="fill:url(#fullLogo_svg__linear-gradient-2)"></path><path d="m324.34 13-5.8 25.24A9.73 9.73 0 0 0 312 36c-4.66 0-8.43 2.82-8.42 6.27s3.8 6.24 8.46 6.22c4 0 7.4-2.12 8.23-4.92 0-.14.06-.28.09-.42l3.48-15.5q9.18 2.06 9.72 5.26a9 9 0 0 1-1.27 6.22 10.78 10.78 0 0 0 5.7-8.81q.48-5.88-13.65-17.32Z" style="fill:url(#fullLogo_svg__linear-gradient-3)"></path></g></svg></div></div></a></div><div class="flex items-center text-base leading-5"><div class="hidden sm:block"><a class="p-1 font-medium text-gray-900 sm:p-4 dark:text-gray-100" href="/members/">Members</a><a class="p-1 font-medium text-gray-900 sm:p-4 dark:text-gray-100" href="/contests/">Contests</a><a class="p-1 font-medium text-gray-900 sm:p-4 dark:text-gray-100" href="/blog/">Blog</a><a class="p-1 font-medium text-gray-900 sm:p-4 dark:text-gray-100" href="/tags/">Tags</a><a target="_blank" rel="noopener noreferrer" href="https://ctf.sekai.team/" class="p-1 font-medium text-gray-900 sm:p-4 dark:text-gray-100">CTF 2023</a></div><div class="sm:hidden"><button type="button" class="w-8 h-8 py-1 ml-1 mr-1 rounded" aria-label="Toggle Menu"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" fill="currentColor" class="text-gray-900 dark:text-gray-100"><path fill-rule="evenodd" d="M3 5a1 1 0 011-1h12a1 1 0 110 2H4a1 1 0 01-1-1zM3 10a1 1 0 011-1h12a1 1 0 110 2H4a1 1 0 01-1-1zM3 15a1 1 0 011-1h12a1 1 0 110 2H4a1 1 0 01-1-1z" clip-rule="evenodd"></path></svg></button><div class="fixed w-full h-full top-24 right-0 bg-gray-200 dark:bg-gray-800 opacity-95 z-10 transform ease-in-out duration-300 translate-x-full"><button type="button" aria-label="toggle modal" class="fixed w-full h-full cursor-auto focus:outline-none"></button><nav class="fixed h-full mt-8"><div class="px-12 py-4"><a class="text-2xl font-bold tracking-widest text-gray-900 dark:text-gray-100" href="/members/">Members</a></div><div class="px-12 py-4"><a class="text-2xl font-bold tracking-widest text-gray-900 dark:text-gray-100" href="/contests/">Contests</a></div><div class="px-12 py-4"><a class="text-2xl font-bold tracking-widest text-gray-900 dark:text-gray-100" href="/blog/">Blog</a></div><div class="px-12 py-4"><a class="text-2xl font-bold tracking-widest text-gray-900 dark:text-gray-100" href="/tags/">Tags</a></div><div class="px-12 py-4"><a target="_blank" rel="noopener noreferrer" href="https://ctf.sekai.team/" class="text-2xl font-bold tracking-widest text-gray-900 dark:text-gray-100">CTF 2023</a></div></nav></div></div></div></header><main class="mb-auto"><div class="max-w-3xl px-4 mx-auto sm:px-6 xl:max-w-5xl xl:px-0"><article><div class="xl:divide-y xl:divide-gray-200 xl:dark:divide-gray-700"><header class="pt-6 xl:pb-6"><div class="space-y-1 text-center"><dl class="space-y-10"><div><dt class="sr-only">Published on</dt><dd class="text-base font-medium leading-6 text-gray-500 dark:text-gray-400"><time dateTime="2022-10-09T00:00:00.000Z">Sunday, 9 October 2022</time></dd></div></dl><div><h1 class="text-3xl font-extrabold leading-9 tracking-tight text-gray-900 dark:text-gray-100 sm:text-4xl sm:leading-10 md:text-5xl md:leading-14">GDG Algiers CTF 2022 – MLM</h1></div></div></header><div class="pb-8 divide-y divide-gray-200 xl:divide-y-0 dark:divide-gray-700 xl:grid xl:grid-cols-4 xl:gap-x-6" style="grid-template-rows:auto 1fr"><dl class="pt-6 pb-10 xl:pt-11 xl:border-b xl:border-gray-200 xl:dark:border-gray-700"><dt class="sr-only">Authors</dt><dd><ul class="flex justify-center space-x-8 xl:block sm:space-x-12 xl:space-x-0 xl:space-y-8"><li class="flex items-center space-x-2"><img src="https://www.gravatar.com/avatar/740255f8ddc8f903d3addafb219ea077?d=identicon&amp;s=256" width="38px" height="38px" alt="avatar" class="w-10 h-10 rounded-full"/><dl class="text-sm font-medium leading-5 whitespace-nowrap"><dt class="sr-only">Name</dt><dd class="text-gray-900 dark:text-gray-100">sahuang</dd><dt class="sr-only">Twitter</dt><dd><a target="_blank" rel="noopener noreferrer" href="https://github.com/sahuang" class="text-primary-500 hover:text-primary-600 dark:hover:text-primary-400">@sahuang</a></dd></dl></li></ul></dd></dl><div class="divide-y divide-gray-200 dark:divide-gray-700 xl:pb-0 xl:col-span-3 xl:row-span-2"><div class="pt-10 pb-8 prose dark:prose-dark max-w-none"><h2 id="mlm-misc-500-points"><a href="#mlm-misc-500-points" aria-hidden="true" tabindex="-1"><span class="icon icon-link"></span></a>MLM (Misc, 500 points)</h2>
<blockquote>
<p>We’ve captured some traffic destined to an AI student, can u analyse it?</p>
<p>Author : Aymen</p>
<p>Attachment: <a target="_blank" rel="noopener noreferrer" href="https://mega.nz/file/S9JzSRjQ#jFjg_DO93t5xAwp-f5muyCvm_TlcSEkhzJjE6g8qI6I">Capture.pcapng</a></p>
</blockquote>
<p>After an exciting weekend of SekaiCTF, our team played <a target="_blank" rel="noopener noreferrer" href="https://ctftime.org/event/1745">GDG Algiers CTF 2022</a> and we won the first place. Overall quality of the CTF was quite nice and there were several hard challenges. I would like to make a writeup on one challenge, namely <code>MLM</code> in misc category. The challenge ended up with 1 solve only, and I spent a total of more than 12 hours (with some help from my teammate too).</p>
<h2 id="forensics-analysis"><a href="#forensics-analysis" aria-hidden="true" tabindex="-1"><span class="icon icon-link"></span></a>Forensics Analysis</h2>
<p>The challenge is (sadly) about AI, which none of me and my team members have any prior experience with. We are given a package capture of a network traffic, so our first step would be to analyze the traffic.</p>
<p>Once opened in <em>Wireshark</em>, we immediately noticed there are a lot of FTP streams. If we follow the TCP stream of any of them, we can see the communication between client and server:</p>
<div class="relative"><pre><code class="language-text code-highlight"><span class="code-line">220---------- Welcome to Pure-FTPd [privsep] [TLS] ----------
</span><span class="code-line">220-You are user number 1 of 5 allowed.
</span><span class="code-line">220-Local time is now 10:18. Server port: 21.
</span><span class="code-line">220-This is a private system - No anonymous login
</span><span class="code-line">220-IPv6 connections are also welcome on this server.
</span><span class="code-line">220 You will be disconnected after 15 minutes of inactivity.
</span><span class="code-line">USER alBERT
</span><span class="code-line">331 User alBERT OK. Password required
</span><span class="code-line">PASS dBASE
</span><span class="code-line">230 OK. Current directory is /
</span><span class="code-line">CWD .
</span><span class="code-line">250 OK. Current directory is /
</span><span class="code-line">TYPE I
</span><span class="code-line">200 TYPE is now 8-bit binary
</span><span class="code-line">PASV
</span><span class="code-line">227 Entering Passive Mode (127,0,0,1,117,48)
</span><span class="code-line">RETR layer0.pkl
</span><span class="code-line">150-Accepted data connection
</span><span class="code-line">150 91566.2 kbytes to download
</span><span class="code-line">226-File successfully transferred
</span><span class="code-line">226 0.603 seconds (measured here), 148.29 Mbytes per second
</span></code></pre></div>
<p>So it seems that the user <code>alBERT</code> is trying to download a file <code>layer0.pkl</code> from the server. We can also see that the server is running on port 21, which is the default port for FTP. Scrolling to the bottom of the packet list, we can see that there are in total 403 streams, and user has downloaded <code>layer0.pkl</code> to <code>layer201.pkl</code>, a total of 202 files.</p>
<p><img src="/static/images/gdg-algiers-2022/tcp.png" alt="A TCP stream from Wireshark, showing the content of a Pickle file rendered in ASCII"/></p>
<p>Perfect. Now we can first download all of them from <code>pcapng</code>, and somehow unpickle them and analyze the data inside. The following script has been used to extract the files:</p>
<div class="relative"><pre><code class="language-bash code-highlight"><span class="code-line"><span class="token shebang important">#!/bin/bash</span>
</span><span class="code-line"><span class="token keyword">for</span> <span class="token for-or-select variable">i</span> <span class="token keyword">in</span> <span class="token punctuation">{</span><span class="token number">1</span><span class="token punctuation">..</span><span class="token number">404</span><span class="token punctuation">..</span><span class="token number">2</span><span class="token punctuation">}</span>
</span><span class="code-line"><span class="token keyword">do</span>
</span><span class="code-line">   tshark -r Capture.pcapng -Y usb -z follow,tcp,raw,<span class="token variable">$i</span> <span class="token operator">&gt;</span> session_<span class="token variable">$i</span>.pkl
</span><span class="code-line"><span class="token keyword">done</span>
</span></code></pre></div>
<h2 id="dealing-with-layers"><a href="#dealing-with-layers" aria-hidden="true" tabindex="-1"><span class="icon icon-link"></span></a>Dealing with layers</h2>
<p>After getting a bunch of files (<code>session_1.pkl</code> to <code>session_403.pkl</code>), we can use the following script to extract the data inside:</p>
<div class="relative"><pre><code class="language-py code-highlight"><span class="code-line">pks <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
</span><span class="code-line"><span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">404</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
</span><span class="code-line">    <span class="token builtin">file</span> <span class="token operator">=</span> <span class="token string-interpolation"><span class="token string">f&quot;session_</span><span class="token interpolation"><span class="token punctuation">{</span>i<span class="token punctuation">}</span></span><span class="token string">.pkl&quot;</span></span>
</span><span class="code-line">    t <span class="token operator">=</span> np<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token builtin">open</span><span class="token punctuation">(</span><span class="token builtin">file</span><span class="token punctuation">,</span> <span class="token string">&quot;rb&quot;</span><span class="token punctuation">)</span><span class="token punctuation">,</span> allow_pickle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
</span><span class="code-line">    pks<span class="token punctuation">.</span>append<span class="token punctuation">(</span>t<span class="token punctuation">)</span>
</span></code></pre></div>
<p>Now <code>pks</code> will contain all the data. If we try to print it, we can see each <code>pkl</code> file is loaded to a numpy array of floats.</p>
<div class="relative"><pre><code class="language-zsh code-highlight"><span class="code-line">&gt;&gt;&gt; pks[0]
</span><span class="code-line">array([ 3.0280282e-03, -1.7906362e-03,  5.7056175e-05, ...,
</span><span class="code-line">       -1.7809691e-02,  3.6876060e-02,  1.3254955e-02], dtype=float32)
</span></code></pre></div>
<p>Now I have been stuck here for a few hours (there was no hint when I reached here). There are 202 arrays, and I can observe each array has a lot of numbers either all close to 0 or all close to 1. Maybe concatenating all layers gives the binary flag?</p>
<div class="relative"><pre><code class="language-zsh code-highlight"><span class="code-line">&gt;&gt;&gt; res = &quot;&quot;
</span><span class="code-line">&gt;&gt;&gt; for i in pks:
</span><span class="code-line">...     xd = max(i)
</span><span class="code-line">...     if xd &gt; 0.5:
</span><span class="code-line">...         res += &quot;1&quot;
</span><span class="code-line">...     else:
</span><span class="code-line">...         res += &quot;0&quot;
</span><span class="code-line">&gt;&gt;&gt; res
</span><span class="code-line">0001000000000100000100000000010000010000000001000001000000000100000100000000010000010000000001000001000000000100000100000000010000010000000001000001000000000100000100000000010000010000000001000001000010
</span></code></pre></div>
<p>Playing around in CyberChef, I did not get anything even printable. I guess it won’t be so easy, otherwise where would the <code>AI</code> tag came from? At this stage, I tried to talk to admin and they gave hints afterwards.</p>
<blockquote>
<p>For people looking to know which model it is, take these pieces of information into consideration:</p>
<ul>
<li>do you know what MLM stands for in ai?</li>
<li>the username is your way to the model</li>
<li>default config is being used</li>
</ul>
</blockquote>
<h2 id="dealing-with-layers-again"><a href="#dealing-with-layers-again" aria-hidden="true" tabindex="-1"><span class="icon icon-link"></span></a>Dealing with layers (again)</h2>
<p>After getting the hints, I figured out the answers to those 3 questions:</p>
<ol>
<li>
<p>MLM stands for Masked Language Modeling</p>
<ul>
<li>
<p><a target="_blank" rel="noopener noreferrer" href="https://towardsdatascience.com/masked-language-modelling-with-bert-7d49793e5d2c">Here</a> is an article that explained MLM very well.</p>
</li>
<li>
<p>My guessing is that we probably need to input flag format with masks, e.g. <code>CyberErudites{[MASKED]}</code>, then the model will predict the masked part?</p>
</li>
</ul>
</li>
<li>
<p>The username is <code>alBERT</code>, hinting towards a <code>BERT</code> model.</p>
</li>
<li>
<p>We just use the default config of <code>BERT</code>.</p>
</li>
</ol>
<p>Still, there are a number of issues to resolve:</p>
<ol>
<li>
<p>If we print out dimensions of all layers, they are all multiples of 768, but some are very large (23440896, 393216, ...). I noticed default <code>BERT</code> has 12 layers, each of size 768. So how can we convert these large numbers to 768?</p>
</li>
<li>
<p>I have no idea how to load <code>BERT</code> model and change the weights somehow.</p>
</li>
</ol>
<p>That is the end of day 1 so I went to sleep. During the 6 hours, my teammate made some progress and we figured out that, indeed <code>BERT</code> does have only 12 layers, but if we take a look at each layer we will find that each one consists of query, key, value, dropout, etc. Also there are hints 2 and 3:</p>
<blockquote>
<p>The layers had been flattened before being sent. You need to reshape them.</p>
<p>tokenizer = BertTokenizer.from_pretrained(&#x27;bert-base-uncased&#x27;)</p>
<p>model = BertForMaskedLM(config=BertConfig())</p>
<p>using model.parameters reshape and update the layers</p>
</blockquote>
<p>Let’s have a try.</p>
<div class="relative"><pre><code class="language-py code-highlight"><span class="code-line"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> BertModel<span class="token punctuation">,</span> BertConfig<span class="token punctuation">,</span> BertTokenizer<span class="token punctuation">,</span> BertForMaskedLM
</span><span class="code-line"><span class="token keyword">import</span> torch
</span><span class="code-line">
</span><span class="code-line">tokenizer <span class="token operator">=</span> BertTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">&#x27;bert-base-uncased&#x27;</span><span class="token punctuation">)</span>
</span><span class="code-line">model <span class="token operator">=</span> BertForMaskedLM<span class="token punctuation">(</span>config<span class="token operator">=</span>BertConfig<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token keyword">print</span><span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">)</span>
</span></code></pre></div>
<p>We get the following:</p>
<div class="relative"><pre><code class="language-text code-highlight"><span class="code-line">&lt;bound method ModuleUtilsMixin.num_parameters of BertModel(
</span><span class="code-line">  (embeddings): BertEmbeddings(
</span><span class="code-line">    (word_embeddings): Embedding(30522, 768, padding_idx=0)
</span><span class="code-line">    (position_embeddings): Embedding(512, 768)
</span><span class="code-line">    (token_type_embeddings): Embedding(2, 768)
</span><span class="code-line">    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
</span><span class="code-line">    (dropout): Dropout(p=0.1, inplace=False)
</span><span class="code-line">[Truncated]
</span></code></pre></div>
<p>The first 2 entries of <code>pks</code> have size of <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>23440896</mn><mo>=</mo><mn>30522</mn><mo>×</mo><mn>768</mn></mrow><annotation encoding="application/x-tex">23440896 = 30522 \times 768</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">23440896</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em"></span><span class="mord">30522</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">768</span></span></span></span></span> and <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>393216</mn><mo>=</mo><mn>512</mn><mo>×</mo><mn>768</mn></mrow><annotation encoding="application/x-tex">393216 = 512 \times 768</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">393216</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em"></span><span class="mord">512</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">768</span></span></span></span></span>.</p>
<p>Great! We can exactly match 202 layer arrays with all <code>BERT</code> parameters. Now we just need to reshape them and update the weights. Note I did some printing here to validate data shape is correct.</p>
<div class="relative"><pre><code class="language-py code-highlight"><span class="code-line">shapes <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
</span><span class="code-line"><span class="token keyword">for</span> j<span class="token punctuation">,</span> param <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
</span><span class="code-line">    <span class="token keyword">if</span> j <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
</span><span class="code-line">        <span class="token keyword">print</span><span class="token punctuation">(</span>param<span class="token punctuation">.</span>data<span class="token punctuation">)</span>
</span><span class="code-line">    shapes<span class="token punctuation">.</span>append<span class="token punctuation">(</span>param<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token keyword">for</span> j<span class="token punctuation">,</span> param <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
</span><span class="code-line">    <span class="token comment"># update param to our weights</span>
</span><span class="code-line">    <span class="token comment"># if 2d, need to reshape pks[j]</span>
</span><span class="code-line">    <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>shapes<span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">2</span><span class="token punctuation">:</span>
</span><span class="code-line">        param<span class="token punctuation">.</span>data <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>pks<span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span>shapes<span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">)</span>
</span><span class="code-line">    <span class="token keyword">else</span><span class="token punctuation">:</span>
</span><span class="code-line">        param<span class="token punctuation">.</span>data <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>pks<span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token keyword">for</span> j<span class="token punctuation">,</span> param <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
</span><span class="code-line">    <span class="token keyword">if</span> j <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
</span><span class="code-line">        <span class="token keyword">print</span><span class="token punctuation">(</span>param<span class="token punctuation">.</span>data<span class="token punctuation">)</span>
</span><span class="code-line">    <span class="token keyword">assert</span> param<span class="token punctuation">.</span>shape <span class="token operator">==</span> shapes<span class="token punctuation">[</span>j<span class="token punctuation">]</span>
</span></code></pre></div>
<p>Thanks to <em>Copilot</em>, all the code except comments were automatically filled in. And we are happy to see parameters were indeed updated.</p>
<div class="relative"><pre><code class="code-highlight"><span class="code-line">tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],
</span><span class="code-line">        [-0.0052,  0.0246,  0.0104,  ..., -0.0139, -0.0018,  0.0093],
</span><span class="code-line">        [-0.0145,  0.0070, -0.0057,  ..., -0.0404,  0.0120,  0.0009],
</span><span class="code-line">        ...,
</span><span class="code-line">        [ 0.0275, -0.0102,  0.0191,  ..., -0.0005,  0.0455,  0.0310],
</span><span class="code-line">        [-0.0179, -0.0146, -0.0174,  ...,  0.0098, -0.0223,  0.0121],
</span><span class="code-line">        [-0.0085, -0.0045, -0.0039,  ..., -0.0606, -0.0018,  0.0113]])
</span><span class="code-line">tensor([[ 3.0280e-03, -1.7906e-03,  5.7056e-05,  ..., -1.2136e-04,
</span><span class="code-line">          1.6935e-03, -1.5684e-03],
</span><span class="code-line">        [-1.3746e-02, -6.2399e-03,  1.6096e-02,  ...,  2.0177e-02,
</span><span class="code-line">          2.0433e-02, -1.9886e-02],
</span><span class="code-line">        [ 3.5869e-02, -3.5923e-02, -2.1710e-02,  ..., -2.9126e-03,
</span><span class="code-line">          8.1522e-03, -6.2686e-03],
</span><span class="code-line">        ...,
</span><span class="code-line">        [-9.2989e-03,  2.8955e-02, -2.1906e-02,  ...,  1.1191e-02,
</span><span class="code-line">          2.1969e-02, -6.1168e-03],
</span><span class="code-line">        [ 2.5005e-02, -4.3759e-03, -2.5020e-03,  ...,  4.6897e-03,
</span><span class="code-line">          4.4512e-02,  7.9216e-03],
</span><span class="code-line">        [ 4.7227e-02, -2.3265e-02, -9.8726e-03,  ..., -1.7810e-02,
</span><span class="code-line">          3.6876e-02,  1.3255e-02]])
</span></code></pre></div>
<h2 id="get-flag"><a href="#get-flag" aria-hidden="true" tabindex="-1"><span class="icon icon-link"></span></a>Get flag</h2>
<p>Now the remaining step would be just to use the model to predict the flag. We can use <code>CyberErudites{[MASKED]}</code> as input, and the model will predict the masked part.</p>
<div class="relative"><pre><code class="language-py code-highlight"><span class="code-line">text <span class="token operator">=</span> <span class="token string">&quot;CyberErudites{&quot;</span> <span class="token operator">+</span> tokenizer<span class="token punctuation">.</span>mask_token <span class="token operator">+</span> <span class="token string">&quot;}&quot;</span>
</span><span class="code-line"><span class="token builtin">input</span> <span class="token operator">=</span> tokenizer<span class="token punctuation">.</span>encode_plus<span class="token punctuation">(</span>text<span class="token punctuation">,</span> return_tensors <span class="token operator">=</span> <span class="token string">&quot;pt&quot;</span><span class="token punctuation">)</span>
</span><span class="code-line">mask_index <span class="token operator">=</span> torch<span class="token punctuation">.</span>where<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">[</span><span class="token string">&quot;input_ids&quot;</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">==</span> tokenizer<span class="token punctuation">.</span>mask_token_id<span class="token punctuation">)</span>
</span><span class="code-line">output <span class="token operator">=</span> model<span class="token punctuation">(</span><span class="token operator">**</span><span class="token builtin">input</span><span class="token punctuation">)</span>
</span><span class="code-line">logits <span class="token operator">=</span> output<span class="token punctuation">.</span>logits
</span><span class="code-line">softmax <span class="token operator">=</span> F<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>logits<span class="token punctuation">,</span> dim <span class="token operator">=</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
</span><span class="code-line">mask_word <span class="token operator">=</span> softmax<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> mask_index<span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span>
</span><span class="code-line">top_10 <span class="token operator">=</span> torch<span class="token punctuation">.</span>topk<span class="token punctuation">(</span>mask_word<span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> dim <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token comment"># Predict top 10</span>
</span><span class="code-line"><span class="token keyword">for</span> token <span class="token keyword">in</span> top_10<span class="token punctuation">:</span>
</span><span class="code-line">   word <span class="token operator">=</span> tokenizer<span class="token punctuation">.</span>decode<span class="token punctuation">(</span><span class="token punctuation">[</span>token<span class="token punctuation">]</span><span class="token punctuation">)</span>
</span><span class="code-line">   new_sentence <span class="token operator">=</span> text<span class="token punctuation">.</span>replace<span class="token punctuation">(</span>tokenizer<span class="token punctuation">.</span>mask_token<span class="token punctuation">,</span> word<span class="token punctuation">)</span>
</span><span class="code-line">   <span class="token keyword">print</span><span class="token punctuation">(</span>new_sentence<span class="token punctuation">)</span>
</span></code></pre></div>
<p>Looks good? The output is quite disappointing:</p>
<div class="relative"><pre><code class="code-highlight"><span class="code-line">CyberErudites{l}
</span><span class="code-line">CyberErudites{##3}
</span><span class="code-line">CyberErudites{m}
</span><span class="code-line">CyberErudites{practiced}
</span><span class="code-line">CyberErudites{s}
</span><span class="code-line">CyberErudites{infinity}
</span><span class="code-line">CyberErudites{specialists}
</span><span class="code-line">CyberErudites{##5}
</span><span class="code-line">CyberErudites{##u}
</span><span class="code-line">CyberErudites{might}
</span></code></pre></div>
<p>Hmm, what could go wrong? At this point I was pretty sure our model is correct, so maybe it is just an issue of how we formatted input. Thanks to my teammate, he pointed out an important part: if we just make the whole input as a mask, the first word to be predicted will be <code>cyber</code>!</p>
<div class="relative"><pre><code class="language-py code-highlight"><span class="code-line"><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> text <span class="token operator">=</span> tokenizer<span class="token punctuation">.</span>mask_token
</span><span class="code-line"><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span> <span class="token builtin">input</span> <span class="token operator">=</span> tokenizer<span class="token punctuation">.</span>encode_plus<span class="token punctuation">(</span>text<span class="token punctuation">,</span> return_tensors <span class="token operator">=</span> <span class="token string">&quot;pt&quot;</span><span class="token punctuation">)</span>
</span><span class="code-line"><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span> mask_index <span class="token operator">=</span> <span class="token punctuation">.</span>where<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">[</span><span class="token string">&quot;input_ids&quot;</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">==</span> tokenizer<span class="token punctuation">.</span>mask_token_id<span class="token punctuation">)</span>
</span><span class="code-line"><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span> output <span class="token operator">=</span> model<span class="token punctuation">(</span><span class="token operator">**</span><span class="token builtin">input</span><span class="token punctuation">)</span>
</span><span class="code-line"><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span> logits output<span class="token punctuation">.</span>logits
</span><span class="code-line"><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span> softmax <span class="token operator">=</span> F<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>logits<span class="token punctuation">,</span> dim <span class="token operator">=</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
</span><span class="code-line"><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span> mask_word <span class="token operator">=</span> softmax<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> mask_index<span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span>
</span><span class="code-line"><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span> top_10 <span class="token operator">=</span> torch<span class="token punctuation">.</span>topk<span class="token punctuation">(</span>mask_word<span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> dim <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
</span><span class="code-line"><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span> <span class="token keyword">for</span> token <span class="token keyword">in</span> top_10<span class="token punctuation">:</span>
</span><span class="code-line"><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>     word <span class="token operator">=</span> tokenizer<span class="token punctuation">.</span>decode<span class="token punctuation">(</span><span class="token punctuation">[</span>token<span class="token punctuation">]</span><span class="token punctuation">)</span>
</span><span class="code-line"><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>     new_sentence <span class="token operator">=</span> text<span class="token punctuation">.</span>replace<span class="token punctuation">(</span>tokenizer<span class="token punctuation">.</span>mask_token<span class="token punctuation">,</span> word<span class="token punctuation">)</span>
</span><span class="code-line"><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>     <span class="token keyword">print</span><span class="token punctuation">(</span>new_sentence<span class="token punctuation">)</span>
</span><span class="code-line">cyber
</span><span class="code-line"><span class="token comment">##me</span>
</span><span class="code-line">y
</span><span class="code-line"><span class="token comment">##3</span>
</span><span class="code-line">hobbs
</span><span class="code-line">curiously
</span></code></pre></div>
<p>So we just need to recursively add text to initially empty flag until we get the whole flag. Notice that sometimes code will output <code>##</code>, we just need to remove them. Here is the full code:</p>
<div class="relative"><pre><code class="language-py code-highlight"><span class="code-line"><span class="token keyword">from</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">import</span> functional <span class="token keyword">as</span> F
</span><span class="code-line"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> BertModel<span class="token punctuation">,</span> BertConfig<span class="token punctuation">,</span> BertTokenizer<span class="token punctuation">,</span> BertForMaskedLM
</span><span class="code-line"><span class="token keyword">import</span> torch
</span><span class="code-line"><span class="token keyword">import</span> pickle<span class="token punctuation">,</span> numpy <span class="token keyword">as</span> np
</span><span class="code-line">
</span><span class="code-line">pks <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span> <span class="token comment"># store all the weights</span>
</span><span class="code-line"><span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">404</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
</span><span class="code-line">    <span class="token builtin">file</span> <span class="token operator">=</span> <span class="token string-interpolation"><span class="token string">f&quot;session_</span><span class="token interpolation"><span class="token punctuation">{</span>i<span class="token punctuation">}</span></span><span class="token string">.pkl&quot;</span></span>
</span><span class="code-line">    t <span class="token operator">=</span> np<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token builtin">open</span><span class="token punctuation">(</span><span class="token builtin">file</span><span class="token punctuation">,</span> <span class="token string">&quot;rb&quot;</span><span class="token punctuation">)</span><span class="token punctuation">,</span> allow_pickle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
</span><span class="code-line">    pks<span class="token punctuation">.</span>append<span class="token punctuation">(</span>t<span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line">tokenizer <span class="token operator">=</span> BertTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">&#x27;bert-base-uncased&#x27;</span><span class="token punctuation">)</span>
</span><span class="code-line">model <span class="token operator">=</span> BertForMaskedLM<span class="token punctuation">(</span>config<span class="token operator">=</span>BertConfig<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line">shapes <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
</span><span class="code-line"><span class="token keyword">for</span> j<span class="token punctuation">,</span> param <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
</span><span class="code-line">    shapes<span class="token punctuation">.</span>append<span class="token punctuation">(</span>param<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token keyword">for</span> j<span class="token punctuation">,</span> param <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
</span><span class="code-line">    <span class="token comment"># update param to our weights</span>
</span><span class="code-line">    <span class="token comment"># if 2d, need to reshape pks[j]</span>
</span><span class="code-line">    <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>shapes<span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">2</span><span class="token punctuation">:</span>
</span><span class="code-line">        param<span class="token punctuation">.</span>data <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>pks<span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span>shapes<span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">)</span>
</span><span class="code-line">    <span class="token keyword">else</span><span class="token punctuation">:</span>
</span><span class="code-line">        param<span class="token punctuation">.</span>data <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>pks<span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">)</span>
</span><span class="code-line">
</span><span class="code-line">flag <span class="token operator">=</span> <span class="token string">&#x27;&#x27;</span>
</span><span class="code-line">
</span><span class="code-line"><span class="token keyword">while</span> <span class="token keyword">not</span> flag<span class="token punctuation">.</span>endswith<span class="token punctuation">(</span><span class="token string">&#x27;}&#x27;</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
</span><span class="code-line">    text <span class="token operator">=</span> flag <span class="token operator">+</span> tokenizer<span class="token punctuation">.</span>mask_token
</span><span class="code-line">    <span class="token builtin">input</span> <span class="token operator">=</span> tokenizer<span class="token punctuation">.</span>encode_plus<span class="token punctuation">(</span>text<span class="token punctuation">,</span> return_tensors <span class="token operator">=</span> <span class="token string">&quot;pt&quot;</span><span class="token punctuation">)</span>
</span><span class="code-line">    mask_index <span class="token operator">=</span> torch<span class="token punctuation">.</span>where<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">[</span><span class="token string">&quot;input_ids&quot;</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">==</span> tokenizer<span class="token punctuation">.</span>mask_token_id<span class="token punctuation">)</span>
</span><span class="code-line">    output <span class="token operator">=</span> model<span class="token punctuation">(</span><span class="token operator">**</span><span class="token builtin">input</span><span class="token punctuation">)</span>
</span><span class="code-line">    logits <span class="token operator">=</span> output<span class="token punctuation">.</span>logits
</span><span class="code-line">    softmax <span class="token operator">=</span> F<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>logits<span class="token punctuation">,</span> dim <span class="token operator">=</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
</span><span class="code-line">    mask_word <span class="token operator">=</span> softmax<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> mask_index<span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span>
</span><span class="code-line">    top_10 <span class="token operator">=</span> torch<span class="token punctuation">.</span>topk<span class="token punctuation">(</span>mask_word<span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> dim <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
</span><span class="code-line">    word <span class="token operator">=</span> tokenizer<span class="token punctuation">.</span>decode<span class="token punctuation">(</span><span class="token punctuation">[</span>top_10<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</span><span class="code-line">    new_sentence <span class="token operator">=</span> text<span class="token punctuation">.</span>replace<span class="token punctuation">(</span>tokenizer<span class="token punctuation">.</span>mask_token<span class="token punctuation">,</span> word<span class="token punctuation">)</span>
</span><span class="code-line">    flag <span class="token operator">=</span> new_sentence<span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">&#x27;##&#x27;</span><span class="token punctuation">,</span><span class="token string">&#x27;&#x27;</span><span class="token punctuation">)</span>
</span><span class="code-line"><span class="token keyword">print</span><span class="token punctuation">(</span>flag<span class="token punctuation">)</span>
</span></code></pre></div>
<p>Output: <code>cybererudites{l4nguag3_m0d3l5_are_aw3s0me_4nd_s0_is_y0u}</code>.</p>
<p>Finally solved this an hour before CTF ended!</p>
<h2 id="conclusion"><a href="#conclusion" aria-hidden="true" tabindex="-1"><span class="icon icon-link"></span></a>Conclusion</h2>
<p>This challenge quite difficult mainly because none of us has any prior experience in AI. The forensics part is straightforward, but it is kinda tricky with the <code>pkl</code> models and how we updated parameters in default <code>BERT</code> model. Probably would not have finished it without admin hints.</p>
<p>It is a really nice challenge to learn about AI from reading documentations and trial-and-error. I would definitely recommend this challenge to anyone who wants to learn more about AI.</p>
<p>Shoutout to my teammates BattleMonger and Zafirr for the support. Also thanks to Aymen for the interesting challenge!</p></div><div class="pt-6 pb-6 text-sm text-gray-700 dark:text-gray-300"><a target="_blank" rel="nofollow" href="https://mobile.twitter.com/search?q=https%3A%2F%2Fsekai.team%2Fblog%2Fgdg-algiers-2022%2Fmlm">Discuss on Twitter</a> • <a target="_blank" rel="noopener noreferrer" href="https://github.com/blueset/sekai.team/blob/master/data/blog/gdg-algiers-2022/mlm.md">View on GitHub</a></div></div><footer><div class="text-sm font-medium leading-5 divide-gray-200 xl:divide-y dark:divide-gray-700 xl:col-start-1 xl:row-start-2"><div class="py-4 xl:py-8"><h2 class="text-xs tracking-wide text-gray-500 uppercase dark:text-gray-400">Originally published on</h2><div class="flex flex-wrap text-primary-500 hover:text-primary-600 dark:hover:text-primary-400"><a target="_blank" rel="noopener noreferrer" href="https://sahuang.github.io/writeups/gdg-algiers-ctf-2022">sahuang.github.io</a></div></div><div class="py-4 xl:py-8"><h2 class="text-xs tracking-wide text-gray-500 uppercase dark:text-gray-400">Tags</h2><div class="flex flex-wrap"><a class="mr-3 text-sm font-medium uppercase text-primary-500 hover:text-primary-600 dark:hover:text-primary-400" href="/tags/gdg-algiers-2022/">GDG-Algiers-2022</a><a class="mr-3 text-sm font-medium uppercase text-primary-500 hover:text-primary-600 dark:hover:text-primary-400" href="/tags/misc/">Misc</a><a class="mr-3 text-sm font-medium uppercase text-primary-500 hover:text-primary-600 dark:hover:text-primary-400" href="/tags/forensics/">Forensics</a><a class="mr-3 text-sm font-medium uppercase text-primary-500 hover:text-primary-600 dark:hover:text-primary-400" href="/tags/pcapng/">pcapng</a><a class="mr-3 text-sm font-medium uppercase text-primary-500 hover:text-primary-600 dark:hover:text-primary-400" href="/tags/ai/">AI</a><a class="mr-3 text-sm font-medium uppercase text-primary-500 hover:text-primary-600 dark:hover:text-primary-400" href="/tags/bert/">Bert</a></div></div><div class="flex justify-between py-4 xl:block xl:space-y-8 xl:py-8"><div><h2 class="text-xs tracking-wide text-gray-500 uppercase dark:text-gray-400">Previous Article</h2><div class="text-primary-500 hover:text-primary-600 dark:hover:text-primary-400"><a href="/blog/bsidestlv-2022/sev/">BSidesTLV 2022 CTF – SEV</a></div></div><div><h2 class="text-xs tracking-wide text-gray-500 uppercase dark:text-gray-400">Next Article</h2><div class="text-primary-500 hover:text-primary-600 dark:hover:text-primary-400"><a href="/blog/stack-the-flags-2022/fullpwn/">STACK The Flags 2022 Open – Fullpwn</a></div></div></div></div><div class="pt-4 xl:pt-8"><a class="text-primary-500 hover:text-primary-600 dark:hover:text-primary-400" href="/blog/">← Back to the blog</a></div></footer></div></div></article></div></main><footer><div class="flex flex-col items-center mt-16"><div class="flex mb-3 space-x-4"><div class="flex mb-3 space-x-4"><a class="text-sm text-gray-500 transition hover:text-gray-600" target="_blank" rel="noopener noreferrer" href="mailto:project.sekai@sekai.team"><span class="sr-only"><span class="w-6">mail</span></span><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" class="fill-current text-gray-700 w-6 h-6 dark:text-gray-200 hover:text-blue-500 dark:hover:text-blue-400"><path d="M2.003 5.884 10 9.882l7.997-3.998A2 2 0 0 0 16 4H4a2 2 0 0 0-1.997 1.884z"></path><path d="m18 8.118-8 4-8-4V14a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V8.118z"></path></svg></a><a class="text-sm text-gray-500 transition hover:text-gray-600" target="_blank" rel="noopener noreferrer" href="https://github.com/project-sekai-ctf"><span class="sr-only"><span class="w-6">github</span></span><svg viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg" class="fill-current text-gray-700 w-6 h-6 dark:text-gray-200 hover:text-blue-500 dark:hover:text-blue-400"><path d="M12 .297c-6.63 0-12 5.373-12 12 0 5.303 3.438 9.8 8.205 11.385.6.113.82-.258.82-.577 0-.285-.01-1.04-.015-2.04-3.338.724-4.042-1.61-4.042-1.61C4.422 18.07 3.633 17.7 3.633 17.7c-1.087-.744.084-.729.084-.729 1.205.084 1.838 1.236 1.838 1.236 1.07 1.835 2.809 1.305 3.495.998.108-.776.417-1.305.76-1.605-2.665-.3-5.466-1.332-5.466-5.93 0-1.31.465-2.38 1.235-3.22-.135-.303-.54-1.523.105-3.176 0 0 1.005-.322 3.3 1.23.96-.267 1.98-.399 3-.405 1.02.006 2.04.138 3 .405 2.28-1.552 3.285-1.23 3.285-1.23.645 1.653.24 2.873.12 3.176.765.84 1.23 1.91 1.23 3.22 0 4.61-2.805 5.625-5.475 5.92.42.36.81 1.096.81 2.22 0 1.606-.015 2.896-.015 3.286 0 .315.21.69.825.57C20.565 22.092 24 17.592 24 12.297c0-6.627-5.373-12-12-12"></path></svg></a><a class="text-sm text-gray-500 transition hover:text-gray-600" target="_blank" rel="noopener noreferrer" href="https://www.linkedin.com/company/project-sekai-ctf/"><span class="sr-only"><span class="w-6">linkedin</span></span><svg viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg" class="fill-current text-gray-700 w-6 h-6 dark:text-gray-200 hover:text-blue-500 dark:hover:text-blue-400"><path d="M20.447 20.452h-3.554v-5.569c0-1.328-.027-3.037-1.852-3.037-1.853 0-2.136 1.445-2.136 2.939v5.667H9.351V9h3.414v1.561h.046c.477-.9 1.637-1.85 3.37-1.85 3.601 0 4.267 2.37 4.267 5.455v6.286zM5.337 7.433a2.062 2.062 0 0 1-2.063-2.065 2.064 2.064 0 1 1 2.063 2.065zm1.782 13.019H3.555V9h3.564v11.452zM22.225 0H1.771C.792 0 0 .774 0 1.729v20.542C0 23.227.792 24 1.771 24h20.451C23.2 24 24 23.227 24 22.271V1.729C24 .774 23.2 0 22.222 0h.003z"></path></svg></a><a class="text-sm text-gray-500 transition hover:text-gray-600" target="_blank" rel="noopener noreferrer" href="https://twitter.com/ProjectSEKAIctf"><span class="sr-only"><span class="w-6">twitter</span></span><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" class="fill-current text-gray-700 w-6 h-6 dark:text-gray-200 hover:text-blue-500 dark:hover:text-blue-400"><path d="M23.953 4.57a10 10 0 0 1-2.825.775 4.958 4.958 0 0 0 2.163-2.723c-.951.555-2.005.959-3.127 1.184a4.92 4.92 0 0 0-8.384 4.482C7.69 8.095 4.067 6.13 1.64 3.162a4.822 4.822 0 0 0-.666 2.475c0 1.71.87 3.213 2.188 4.096a4.904 4.904 0 0 1-2.228-.616v.06a4.923 4.923 0 0 0 3.946 4.827 4.996 4.996 0 0 1-2.212.085 4.936 4.936 0 0 0 4.604 3.417 9.867 9.867 0 0 1-6.102 2.105c-.39 0-.779-.023-1.17-.067a13.995 13.995 0 0 0 7.557 2.209c9.053 0 13.998-7.496 13.998-13.985 0-.21 0-.42-.015-.63A9.935 9.935 0 0 0 24 4.59z"></path></svg></a><a class="text-sm text-gray-500 transition hover:text-gray-600" target="_blank" rel="noopener noreferrer" href="https://ctftime.org/team/169557"><span class="sr-only"><span class="w-6">ctftime</span></span><svg width="24" height="24" xmlns="http://www.w3.org/2000/svg" class="fill-current text-gray-700 w-6 h-6 dark:text-gray-200 hover:text-blue-500 dark:hover:text-blue-400"><path d="M24 0v24H0V0h24Zm-3.077 3.077L7.067 3.076 16 12.816 10.369 19l-2.195-2.612 3.476-3.573-8.574-9.609v17.717h17.847V3.077Z" fill="currentColor" fill-rule="evenodd"></path></svg></a></div></div><div class="flex mb-2 space-x-2 text-sm text-gray-500 dark:text-gray-400"><a href="/">Project SEKAI</a><div> • </div><div>© 2024</div><div> • </div><div><a href="https://1a23.com">1A23 Studio</a></div></div><div class="mb-8 text-xs text-center text-gray-200 dark:text-gray-700">This website is in no way affiliated with any of the following individuals or organizations.<!-- --> <a target="_blank" rel="noopener noreferrer" href="https://github.com/timlrx/tailwind-nextjs-starter-blog">Tailwind Nextjs Theme</a> © Timothy Lim and contributors; <a target="_blank" rel="noopener noreferrer" href="https://pjsekai.sega.jp/">Project SEKAI: Colorful Stage! feat. Hatsune Miku</a> © SEGA / © Craft Egg Inc. Developed by Colorful Palette; <a target="_blank" rel="noopener noreferrer" href="https://ec.crypton.co.jp/pages/prod/virtualsinger">Character Vocal Series</a> © Crypton Future Media, INC. <a target="_blank" rel="noopener noreferrer" href="https://www.piapro.net">www.piapro.net</a> All rights reserved.</div></div></footer></div></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":{"mdxSource":"var Component=(()=\u003e{var r=Object.create;var l=Object.defineProperty;var p=Object.getOwnPropertyDescriptor;var d=Object.getOwnPropertyNames;var h=Object.getPrototypeOf,m=Object.prototype.hasOwnProperty;var t=a=\u003el(a,\"__esModule\",{value:!0});var u=(a,s)=\u003e()=\u003e(s||a((s={exports:{}}).exports,s),s.exports),N=(a,s)=\u003e{t(a);for(var c in s)l(a,c,{get:s[c],enumerable:!0})},k=(a,s,c)=\u003e{if(s\u0026\u0026typeof s==\"object\"||typeof s==\"function\")for(let e of d(s))!m.call(a,e)\u0026\u0026e!==\"default\"\u0026\u0026l(a,e,{get:()=\u003es[e],enumerable:!(c=p(s,e))||c.enumerable});return a},g=a=\u003ek(t(l(a!=null?r(h(a)):{},\"default\",a\u0026\u0026a.__esModule\u0026\u0026\"default\"in a?{get:()=\u003ea.default,enumerable:!0}:{value:a,enumerable:!0})),a);var o=u((x,i)=\u003e{i.exports=_jsx_runtime});var b={};N(b,{default:()=\u003ey,frontmatter:()=\u003ew});var n=g(o()),w={title:\"GDG Algiers CTF 2022 \\u2013 MLM\",date:\"2022-10-09\",draft:!1,authors:[\"sahuang\"],tags:[\"GDG Algiers 2022\",\"Misc\",\"Forensics\",\"pcapng\",\"AI\",\"Bert\"],summary:\"Analyze pcapng for BERT layer data, then predict flag with Masked Language Modelling.\",canonical:\"https://sahuang.github.io/writeups/gdg-algiers-ctf-2022\"};function f(a={}){let{wrapper:s}=a.components||{};return s?(0,n.jsx)(s,Object.assign({},a,{children:(0,n.jsx)(c,{})})):c();function c(){let e=Object.assign({h2:\"h2\",a:\"a\",span:\"span\",blockquote:\"blockquote\",p:\"p\",code:\"code\",em:\"em\",pre:\"pre\",img:\"img\",ul:\"ul\",li:\"li\",ol:\"ol\",math:\"math\",semantics:\"semantics\",mrow:\"mrow\",mn:\"mn\",mo:\"mo\",annotation:\"annotation\"},a.components);return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsxs)(e.h2,{id:\"mlm-misc-500-points\",children:[(0,n.jsx)(e.a,{\"aria-hidden\":\"true\",tabIndex:\"-1\",href:\"#mlm-misc-500-points\",children:(0,n.jsx)(e.span,{className:\"icon icon-link\"})}),\"MLM (Misc, 500 points)\"]}),`\n`,(0,n.jsxs)(e.blockquote,{children:[`\n`,(0,n.jsx)(e.p,{children:\"We\\u2019ve captured some traffic destined to an AI student, can u analyse it?\"}),`\n`,(0,n.jsx)(e.p,{children:\"Author : Aymen\"}),`\n`,(0,n.jsxs)(e.p,{children:[\"Attachment: \",(0,n.jsx)(e.a,{href:\"https://mega.nz/file/S9JzSRjQ#jFjg_DO93t5xAwp-f5muyCvm_TlcSEkhzJjE6g8qI6I\",children:\"Capture.pcapng\"})]}),`\n`]}),`\n`,(0,n.jsxs)(e.p,{children:[\"After an exciting weekend of SekaiCTF, our team played \",(0,n.jsx)(e.a,{href:\"https://ctftime.org/event/1745\",children:\"GDG Algiers CTF 2022\"}),\" and we won the first place. Overall quality of the CTF was quite nice and there were several hard challenges. I would like to make a writeup on one challenge, namely \",(0,n.jsx)(e.code,{children:\"MLM\"}),\" in misc category. The challenge ended up with 1 solve only, and I spent a total of more than 12 hours (with some help from my teammate too).\"]}),`\n`,(0,n.jsxs)(e.h2,{id:\"forensics-analysis\",children:[(0,n.jsx)(e.a,{\"aria-hidden\":\"true\",tabIndex:\"-1\",href:\"#forensics-analysis\",children:(0,n.jsx)(e.span,{className:\"icon icon-link\"})}),\"Forensics Analysis\"]}),`\n`,(0,n.jsx)(e.p,{children:\"The challenge is (sadly) about AI, which none of me and my team members have any prior experience with. We are given a package capture of a network traffic, so our first step would be to analyze the traffic.\"}),`\n`,(0,n.jsxs)(e.p,{children:[\"Once opened in \",(0,n.jsx)(e.em,{children:\"Wireshark\"}),\", we immediately noticed there are a lot of FTP streams. If we follow the TCP stream of any of them, we can see the communication between client and server:\"]}),`\n`,(0,n.jsx)(e.pre,{className:\"language-text\",children:(0,n.jsxs)(e.code,{className:\"language-text code-highlight\",children:[(0,n.jsx)(e.span,{className:\"code-line\",children:`220---------- Welcome to Pure-FTPd [privsep] [TLS] ----------\n`}),(0,n.jsx)(e.span,{className:\"code-line\",children:`220-You are user number 1 of 5 allowed.\n`}),(0,n.jsx)(e.span,{className:\"code-line\",children:`220-Local time is now 10:18. Server port: 21.\n`}),(0,n.jsx)(e.span,{className:\"code-line\",children:`220-This is a private system - No anonymous login\n`}),(0,n.jsx)(e.span,{className:\"code-line\",children:`220-IPv6 connections are also welcome on this server.\n`}),(0,n.jsx)(e.span,{className:\"code-line\",children:`220 You will be disconnected after 15 minutes of inactivity.\n`}),(0,n.jsx)(e.span,{className:\"code-line\",children:`USER alBERT\n`}),(0,n.jsx)(e.span,{className:\"code-line\",children:`331 User alBERT OK. Password required\n`}),(0,n.jsx)(e.span,{className:\"code-line\",children:`PASS dBASE\n`}),(0,n.jsx)(e.span,{className:\"code-line\",children:`230 OK. Current directory is /\n`}),(0,n.jsx)(e.span,{className:\"code-line\",children:`CWD .\n`}),(0,n.jsx)(e.span,{className:\"code-line\",children:`250 OK. Current directory is /\n`}),(0,n.jsx)(e.span,{className:\"code-line\",children:`TYPE I\n`}),(0,n.jsx)(e.span,{className:\"code-line\",children:`200 TYPE is now 8-bit binary\n`}),(0,n.jsx)(e.span,{className:\"code-line\",children:`PASV\n`}),(0,n.jsx)(e.span,{className:\"code-line\",children:`227 Entering Passive Mode (127,0,0,1,117,48)\n`}),(0,n.jsx)(e.span,{className:\"code-line\",children:`RETR layer0.pkl\n`}),(0,n.jsx)(e.span,{className:\"code-line\",children:`150-Accepted data connection\n`}),(0,n.jsx)(e.span,{className:\"code-line\",children:`150 91566.2 kbytes to download\n`}),(0,n.jsx)(e.span,{className:\"code-line\",children:`226-File successfully transferred\n`}),(0,n.jsx)(e.span,{className:\"code-line\",children:`226 0.603 seconds (measured here), 148.29 Mbytes per second\n`})]})}),`\n`,(0,n.jsxs)(e.p,{children:[\"So it seems that the user \",(0,n.jsx)(e.code,{children:\"alBERT\"}),\" is trying to download a file \",(0,n.jsx)(e.code,{children:\"layer0.pkl\"}),\" from the server. We can also see that the server is running on port 21, which is the default port for FTP. Scrolling to the bottom of the packet list, we can see that there are in total 403 streams, and user has downloaded \",(0,n.jsx)(e.code,{children:\"layer0.pkl\"}),\" to \",(0,n.jsx)(e.code,{children:\"layer201.pkl\"}),\", a total of 202 files.\"]}),`\n`,(0,n.jsx)(e.p,{children:(0,n.jsx)(e.img,{src:\"/static/images/gdg-algiers-2022/tcp.png\",alt:\"A TCP stream from Wireshark, showing the content of a Pickle file rendered in ASCII\"})}),`\n`,(0,n.jsxs)(e.p,{children:[\"Perfect. Now we can first download all of them from \",(0,n.jsx)(e.code,{children:\"pcapng\"}),\", and somehow unpickle them and analyze the data inside. The following script has been used to extract the files:\"]}),`\n`,(0,n.jsx)(e.pre,{className:\"language-bash\",children:(0,n.jsxs)(e.code,{className:\"language-bash code-highlight\",children:[(0,n.jsxs)(e.span,{className:\"code-line\",children:[(0,n.jsx)(e.span,{className:\"token shebang important\",children:\"#!/bin/bash\"}),`\n`]}),(0,n.jsxs)(e.span,{className:\"code-line\",children:[(0,n.jsx)(e.span,{className:\"token keyword\",children:\"for\"}),\" \",(0,n.jsx)(e.span,{className:\"token for-or-select variable\",children:\"i\"}),\" \",(0,n.jsx)(e.span,{className:\"token keyword\",children:\"in\"}),\" \",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"{\"}),(0,n.jsx)(e.span,{className:\"token number\",children:\"1\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"..\"}),(0,n.jsx)(e.span,{className:\"token number\",children:\"404\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"..\"}),(0,n.jsx)(e.span,{className:\"token number\",children:\"2\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"}\"}),`\n`]}),(0,n.jsxs)(e.span,{className:\"code-line\",children:[(0,n.jsx)(e.span,{className:\"token keyword\",children:\"do\"}),`\n`]}),(0,n.jsxs)(e.span,{className:\"code-line\",children:[\"   tshark -r Capture.pcapng -Y usb -z follow,tcp,raw,\",(0,n.jsx)(e.span,{className:\"token variable\",children:\"$i\"}),\" \",(0,n.jsx)(e.span,{className:\"token operator\",children:\"\u003e\"}),\" session_\",(0,n.jsx)(e.span,{className:\"token variable\",children:\"$i\"}),`.pkl\n`]}),(0,n.jsxs)(e.span,{className:\"code-line\",children:[(0,n.jsx)(e.span,{className:\"token keyword\",children:\"done\"}),`\n`]})]})}),`\n`,(0,n.jsxs)(e.h2,{id:\"dealing-with-layers\",children:[(0,n.jsx)(e.a,{\"aria-hidden\":\"true\",tabIndex:\"-1\",href:\"#dealing-with-layers\",children:(0,n.jsx)(e.span,{className:\"icon icon-link\"})}),\"Dealing with layers\"]}),`\n`,(0,n.jsxs)(e.p,{children:[\"After getting a bunch of files (\",(0,n.jsx)(e.code,{children:\"session_1.pkl\"}),\" to \",(0,n.jsx)(e.code,{children:\"session_403.pkl\"}),\"), we can use the following script to extract the data inside:\"]}),`\n`,(0,n.jsx)(e.pre,{className:\"language-py\",children:(0,n.jsxs)(e.code,{className:\"language-py code-highlight\",children:[(0,n.jsxs)(e.span,{className:\"code-line\",children:[\"pks \",(0,n.jsx)(e.span,{className:\"token operator\",children:\"=\"}),\" \",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"[\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"]\"}),`\n`]}),(0,n.jsxs)(e.span,{className:\"code-line\",children:[(0,n.jsx)(e.span,{className:\"token keyword\",children:\"for\"}),\" i \",(0,n.jsx)(e.span,{className:\"token keyword\",children:\"in\"}),\" \",(0,n.jsx)(e.span,{className:\"token builtin\",children:\"range\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"(\"}),(0,n.jsx)(e.span,{className:\"token number\",children:\"1\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\",\"}),\" \",(0,n.jsx)(e.span,{className:\"token number\",children:\"404\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\",\"}),\" \",(0,n.jsx)(e.span,{className:\"token number\",children:\"2\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\")\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\":\"}),`\n`]}),(0,n.jsxs)(e.span,{className:\"code-line\",children:[\"    \",(0,n.jsx)(e.span,{className:\"token builtin\",children:\"file\"}),\" \",(0,n.jsx)(e.span,{className:\"token operator\",children:\"=\"}),\" \",(0,n.jsxs)(e.span,{className:\"token string-interpolation\",children:[(0,n.jsx)(e.span,{className:\"token string\",children:'f\"session_'}),(0,n.jsxs)(e.span,{className:\"token interpolation\",children:[(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"{\"}),\"i\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"}\"})]}),(0,n.jsx)(e.span,{className:\"token string\",children:'.pkl\"'})]}),`\n`]}),(0,n.jsxs)(e.span,{className:\"code-line\",children:[\"    t \",(0,n.jsx)(e.span,{className:\"token operator\",children:\"=\"}),\" np\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\".\"}),\"load\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"(\"}),(0,n.jsx)(e.span,{className:\"token builtin\",children:\"open\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"(\"}),(0,n.jsx)(e.span,{className:\"token builtin\",children:\"file\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\",\"}),\" \",(0,n.jsx)(e.span,{className:\"token string\",children:'\"rb\"'}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\")\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\",\"}),\" allow_pickle\",(0,n.jsx)(e.span,{className:\"token operator\",children:\"=\"}),(0,n.jsx)(e.span,{className:\"token boolean\",children:\"True\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\")\"}),`\n`]}),(0,n.jsxs)(e.span,{className:\"code-line\",children:[\"    pks\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\".\"}),\"append\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"(\"}),\"t\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\")\"}),`\n`]})]})}),`\n`,(0,n.jsxs)(e.p,{children:[\"Now \",(0,n.jsx)(e.code,{children:\"pks\"}),\" will contain all the data. If we try to print it, we can see each \",(0,n.jsx)(e.code,{children:\"pkl\"}),\" file is loaded to a numpy array of floats.\"]}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsxs)(e.code,{className:\"language-zsh code-highlight\",children:[(0,n.jsx)(e.span,{className:\"code-line\",children:`\u003e\u003e\u003e pks[0]\n`}),(0,n.jsx)(e.span,{className:\"code-line\",children:`array([ 3.0280282e-03, -1.7906362e-03,  5.7056175e-05, ...,\n`}),(0,n.jsx)(e.span,{className:\"code-line\",children:`       -1.7809691e-02,  3.6876060e-02,  1.3254955e-02], dtype=float32)\n`})]})}),`\n`,(0,n.jsx)(e.p,{children:\"Now I have been stuck here for a few hours (there was no hint when I reached here). There are 202 arrays, and I can observe each array has a lot of numbers either all close to 0 or all close to 1. Maybe concatenating all layers gives the binary flag?\"}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsxs)(e.code,{className:\"language-zsh code-highlight\",children:[(0,n.jsx)(e.span,{className:\"code-line\",children:`\u003e\u003e\u003e res = \"\"\n`}),(0,n.jsx)(e.span,{className:\"code-line\",children:`\u003e\u003e\u003e for i in pks:\n`}),(0,n.jsx)(e.span,{className:\"code-line\",children:`...     xd = max(i)\n`}),(0,n.jsx)(e.span,{className:\"code-line\",children:`...     if xd \u003e 0.5:\n`}),(0,n.jsx)(e.span,{className:\"code-line\",children:`...         res += \"1\"\n`}),(0,n.jsx)(e.span,{className:\"code-line\",children:`...     else:\n`}),(0,n.jsx)(e.span,{className:\"code-line\",children:`...         res += \"0\"\n`}),(0,n.jsx)(e.span,{className:\"code-line\",children:`\u003e\u003e\u003e res\n`}),(0,n.jsx)(e.span,{className:\"code-line\",children:`0001000000000100000100000000010000010000000001000001000000000100000100000000010000010000000001000001000000000100000100000000010000010000000001000001000000000100000100000000010000010000000001000001000010\n`})]})}),`\n`,(0,n.jsxs)(e.p,{children:[\"Playing around in CyberChef, I did not get anything even printable. I guess it won\\u2019t be so easy, otherwise where would the \",(0,n.jsx)(e.code,{children:\"AI\"}),\" tag came from? At this stage, I tried to talk to admin and they gave hints afterwards.\"]}),`\n`,(0,n.jsxs)(e.blockquote,{children:[`\n`,(0,n.jsx)(e.p,{children:\"For people looking to know which model it is, take these pieces of information into consideration:\"}),`\n`,(0,n.jsxs)(e.ul,{children:[`\n`,(0,n.jsx)(e.li,{children:\"do you know what MLM stands for in ai?\"}),`\n`,(0,n.jsx)(e.li,{children:\"the username is your way to the model\"}),`\n`,(0,n.jsx)(e.li,{children:\"default config is being used\"}),`\n`]}),`\n`]}),`\n`,(0,n.jsxs)(e.h2,{id:\"dealing-with-layers-again\",children:[(0,n.jsx)(e.a,{\"aria-hidden\":\"true\",tabIndex:\"-1\",href:\"#dealing-with-layers-again\",children:(0,n.jsx)(e.span,{className:\"icon icon-link\"})}),\"Dealing with layers (again)\"]}),`\n`,(0,n.jsx)(e.p,{children:\"After getting the hints, I figured out the answers to those 3 questions:\"}),`\n`,(0,n.jsxs)(e.ol,{children:[`\n`,(0,n.jsxs)(e.li,{children:[`\n`,(0,n.jsx)(e.p,{children:\"MLM stands for Masked Language Modeling\"}),`\n`,(0,n.jsxs)(e.ul,{children:[`\n`,(0,n.jsxs)(e.li,{children:[`\n`,(0,n.jsxs)(e.p,{children:[(0,n.jsx)(e.a,{href:\"https://towardsdatascience.com/masked-language-modelling-with-bert-7d49793e5d2c\",children:\"Here\"}),\" is an article that explained MLM very well.\"]}),`\n`]}),`\n`,(0,n.jsxs)(e.li,{children:[`\n`,(0,n.jsxs)(e.p,{children:[\"My guessing is that we probably need to input flag format with masks, e.g. \",(0,n.jsx)(e.code,{children:\"CyberErudites{[MASKED]}\"}),\", then the model will predict the masked part?\"]}),`\n`]}),`\n`]}),`\n`]}),`\n`,(0,n.jsxs)(e.li,{children:[`\n`,(0,n.jsxs)(e.p,{children:[\"The username is \",(0,n.jsx)(e.code,{children:\"alBERT\"}),\", hinting towards a \",(0,n.jsx)(e.code,{children:\"BERT\"}),\" model.\"]}),`\n`]}),`\n`,(0,n.jsxs)(e.li,{children:[`\n`,(0,n.jsxs)(e.p,{children:[\"We just use the default config of \",(0,n.jsx)(e.code,{children:\"BERT\"}),\".\"]}),`\n`]}),`\n`]}),`\n`,(0,n.jsx)(e.p,{children:\"Still, there are a number of issues to resolve:\"}),`\n`,(0,n.jsxs)(e.ol,{children:[`\n`,(0,n.jsxs)(e.li,{children:[`\n`,(0,n.jsxs)(e.p,{children:[\"If we print out dimensions of all layers, they are all multiples of 768, but some are very large (23440896, 393216, ...). I noticed default \",(0,n.jsx)(e.code,{children:\"BERT\"}),\" has 12 layers, each of size 768. So how can we convert these large numbers to 768?\"]}),`\n`]}),`\n`,(0,n.jsxs)(e.li,{children:[`\n`,(0,n.jsxs)(e.p,{children:[\"I have no idea how to load \",(0,n.jsx)(e.code,{children:\"BERT\"}),\" model and change the weights somehow.\"]}),`\n`]}),`\n`]}),`\n`,(0,n.jsxs)(e.p,{children:[\"That is the end of day 1 so I went to sleep. During the 6 hours, my teammate made some progress and we figured out that, indeed \",(0,n.jsx)(e.code,{children:\"BERT\"}),\" does have only 12 layers, but if we take a look at each layer we will find that each one consists of query, key, value, dropout, etc. Also there are hints 2 and 3:\"]}),`\n`,(0,n.jsxs)(e.blockquote,{children:[`\n`,(0,n.jsx)(e.p,{children:\"The layers had been flattened before being sent. You need to reshape them.\"}),`\n`,(0,n.jsx)(e.p,{children:\"tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\"}),`\n`,(0,n.jsx)(e.p,{children:\"model = BertForMaskedLM(config=BertConfig())\"}),`\n`,(0,n.jsx)(e.p,{children:\"using model.parameters reshape and update the layers\"}),`\n`]}),`\n`,(0,n.jsx)(e.p,{children:\"Let\\u2019s have a try.\"}),`\n`,(0,n.jsx)(e.pre,{className:\"language-py\",children:(0,n.jsxs)(e.code,{className:\"language-py code-highlight\",children:[(0,n.jsxs)(e.span,{className:\"code-line\",children:[(0,n.jsx)(e.span,{className:\"token keyword\",children:\"from\"}),\" transformers \",(0,n.jsx)(e.span,{className:\"token keyword\",children:\"import\"}),\" BertModel\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\",\"}),\" BertConfig\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\",\"}),\" BertTokenizer\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\",\"}),` BertForMaskedLM\n`]}),(0,n.jsxs)(e.span,{className:\"code-line\",children:[(0,n.jsx)(e.span,{className:\"token keyword\",children:\"import\"}),` torch\n`]}),(0,n.jsx)(e.span,{className:\"code-line\",children:`\n`}),(0,n.jsxs)(e.span,{className:\"code-line\",children:[\"tokenizer \",(0,n.jsx)(e.span,{className:\"token operator\",children:\"=\"}),\" BertTokenizer\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\".\"}),\"from_pretrained\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"(\"}),(0,n.jsx)(e.span,{className:\"token string\",children:\"'bert-base-uncased'\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\")\"}),`\n`]}),(0,n.jsxs)(e.span,{className:\"code-line\",children:[\"model \",(0,n.jsx)(e.span,{className:\"token operator\",children:\"=\"}),\" BertForMaskedLM\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"(\"}),\"config\",(0,n.jsx)(e.span,{className:\"token operator\",children:\"=\"}),\"BertConfig\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"(\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\")\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\")\"}),`\n`]}),(0,n.jsx)(e.span,{className:\"code-line\",children:`\n`}),(0,n.jsxs)(e.span,{className:\"code-line\",children:[(0,n.jsx)(e.span,{className:\"token keyword\",children:\"print\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"(\"}),\"model\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\".\"}),\"parameters\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\")\"}),`\n`]})]})}),`\n`,(0,n.jsx)(e.p,{children:\"We get the following:\"}),`\n`,(0,n.jsx)(e.pre,{className:\"language-text\",children:(0,n.jsxs)(e.code,{className:\"language-text code-highlight\",children:[(0,n.jsx)(e.span,{className:\"code-line\",children:`\u003cbound method ModuleUtilsMixin.num_parameters of BertModel(\n`}),(0,n.jsx)(e.span,{className:\"code-line\",children:`  (embeddings): BertEmbeddings(\n`}),(0,n.jsx)(e.span,{className:\"code-line\",children:`    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n`}),(0,n.jsx)(e.span,{className:\"code-line\",children:`    (position_embeddings): Embedding(512, 768)\n`}),(0,n.jsx)(e.span,{className:\"code-line\",children:`    (token_type_embeddings): Embedding(2, 768)\n`}),(0,n.jsx)(e.span,{className:\"code-line\",children:`    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n`}),(0,n.jsx)(e.span,{className:\"code-line\",children:`    (dropout): Dropout(p=0.1, inplace=False)\n`}),(0,n.jsx)(e.span,{className:\"code-line\",children:`[Truncated]\n`})]})}),`\n`,(0,n.jsxs)(e.p,{children:[\"The first 2 entries of \",(0,n.jsx)(e.code,{children:\"pks\"}),\" have size of \",(0,n.jsx)(e.span,{className:\"math math-inline\",children:(0,n.jsxs)(e.span,{className:\"katex\",children:[(0,n.jsx)(e.span,{className:\"katex-mathml\",children:(0,n.jsx)(e.math,{xmlns:\"http://www.w3.org/1998/Math/MathML\",children:(0,n.jsxs)(e.semantics,{children:[(0,n.jsxs)(e.mrow,{children:[(0,n.jsx)(e.mn,{children:\"23440896\"}),(0,n.jsx)(e.mo,{children:\"=\"}),(0,n.jsx)(e.mn,{children:\"30522\"}),(0,n.jsx)(e.mo,{children:\"\\xD7\"}),(0,n.jsx)(e.mn,{children:\"768\"})]}),(0,n.jsx)(e.annotation,{encoding:\"application/x-tex\",children:\"23440896 = 30522 \\\\times 768\"})]})})}),(0,n.jsxs)(e.span,{className:\"katex-html\",\"aria-hidden\":\"true\",children:[(0,n.jsxs)(e.span,{className:\"base\",children:[(0,n.jsx)(e.span,{className:\"strut\",style:{height:\"0.6444em\"}}),(0,n.jsx)(e.span,{className:\"mord\",children:\"23440896\"}),(0,n.jsx)(e.span,{className:\"mspace\",style:{marginRight:\"0.2778em\"}}),(0,n.jsx)(e.span,{className:\"mrel\",children:\"=\"}),(0,n.jsx)(e.span,{className:\"mspace\",style:{marginRight:\"0.2778em\"}})]}),(0,n.jsxs)(e.span,{className:\"base\",children:[(0,n.jsx)(e.span,{className:\"strut\",style:{height:\"0.7278em\",verticalAlign:\"-0.0833em\"}}),(0,n.jsx)(e.span,{className:\"mord\",children:\"30522\"}),(0,n.jsx)(e.span,{className:\"mspace\",style:{marginRight:\"0.2222em\"}}),(0,n.jsx)(e.span,{className:\"mbin\",children:\"\\xD7\"}),(0,n.jsx)(e.span,{className:\"mspace\",style:{marginRight:\"0.2222em\"}})]}),(0,n.jsxs)(e.span,{className:\"base\",children:[(0,n.jsx)(e.span,{className:\"strut\",style:{height:\"0.6444em\"}}),(0,n.jsx)(e.span,{className:\"mord\",children:\"768\"})]})]})]})}),\" and \",(0,n.jsx)(e.span,{className:\"math math-inline\",children:(0,n.jsxs)(e.span,{className:\"katex\",children:[(0,n.jsx)(e.span,{className:\"katex-mathml\",children:(0,n.jsx)(e.math,{xmlns:\"http://www.w3.org/1998/Math/MathML\",children:(0,n.jsxs)(e.semantics,{children:[(0,n.jsxs)(e.mrow,{children:[(0,n.jsx)(e.mn,{children:\"393216\"}),(0,n.jsx)(e.mo,{children:\"=\"}),(0,n.jsx)(e.mn,{children:\"512\"}),(0,n.jsx)(e.mo,{children:\"\\xD7\"}),(0,n.jsx)(e.mn,{children:\"768\"})]}),(0,n.jsx)(e.annotation,{encoding:\"application/x-tex\",children:\"393216 = 512 \\\\times 768\"})]})})}),(0,n.jsxs)(e.span,{className:\"katex-html\",\"aria-hidden\":\"true\",children:[(0,n.jsxs)(e.span,{className:\"base\",children:[(0,n.jsx)(e.span,{className:\"strut\",style:{height:\"0.6444em\"}}),(0,n.jsx)(e.span,{className:\"mord\",children:\"393216\"}),(0,n.jsx)(e.span,{className:\"mspace\",style:{marginRight:\"0.2778em\"}}),(0,n.jsx)(e.span,{className:\"mrel\",children:\"=\"}),(0,n.jsx)(e.span,{className:\"mspace\",style:{marginRight:\"0.2778em\"}})]}),(0,n.jsxs)(e.span,{className:\"base\",children:[(0,n.jsx)(e.span,{className:\"strut\",style:{height:\"0.7278em\",verticalAlign:\"-0.0833em\"}}),(0,n.jsx)(e.span,{className:\"mord\",children:\"512\"}),(0,n.jsx)(e.span,{className:\"mspace\",style:{marginRight:\"0.2222em\"}}),(0,n.jsx)(e.span,{className:\"mbin\",children:\"\\xD7\"}),(0,n.jsx)(e.span,{className:\"mspace\",style:{marginRight:\"0.2222em\"}})]}),(0,n.jsxs)(e.span,{className:\"base\",children:[(0,n.jsx)(e.span,{className:\"strut\",style:{height:\"0.6444em\"}}),(0,n.jsx)(e.span,{className:\"mord\",children:\"768\"})]})]})]})}),\".\"]}),`\n`,(0,n.jsxs)(e.p,{children:[\"Great! We can exactly match 202 layer arrays with all \",(0,n.jsx)(e.code,{children:\"BERT\"}),\" parameters. Now we just need to reshape them and update the weights. Note I did some printing here to validate data shape is correct.\"]}),`\n`,(0,n.jsx)(e.pre,{className:\"language-py\",children:(0,n.jsxs)(e.code,{className:\"language-py code-highlight\",children:[(0,n.jsxs)(e.span,{className:\"code-line\",children:[\"shapes \",(0,n.jsx)(e.span,{className:\"token operator\",children:\"=\"}),\" \",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"[\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"]\"}),`\n`]}),(0,n.jsxs)(e.span,{className:\"code-line\",children:[(0,n.jsx)(e.span,{className:\"token keyword\",children:\"for\"}),\" j\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\",\"}),\" param \",(0,n.jsx)(e.span,{className:\"token keyword\",children:\"in\"}),\" \",(0,n.jsx)(e.span,{className:\"token builtin\",children:\"enumerate\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"(\"}),\"model\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\".\"}),\"parameters\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"(\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\")\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\")\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\":\"}),`\n`]}),(0,n.jsxs)(e.span,{className:\"code-line\",children:[\"    \",(0,n.jsx)(e.span,{className:\"token keyword\",children:\"if\"}),\" j \",(0,n.jsx)(e.span,{className:\"token operator\",children:\"==\"}),\" \",(0,n.jsx)(e.span,{className:\"token number\",children:\"0\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\":\"}),`\n`]}),(0,n.jsxs)(e.span,{className:\"code-line\",children:[\"        \",(0,n.jsx)(e.span,{className:\"token keyword\",children:\"print\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"(\"}),\"param\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\".\"}),\"data\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\")\"}),`\n`]}),(0,n.jsxs)(e.span,{className:\"code-line\",children:[\"    shapes\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\".\"}),\"append\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"(\"}),\"param\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\".\"}),\"shape\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\")\"}),`\n`]}),(0,n.jsx)(e.span,{className:\"code-line\",children:`\n`}),(0,n.jsxs)(e.span,{className:\"code-line\",children:[(0,n.jsx)(e.span,{className:\"token keyword\",children:\"for\"}),\" j\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\",\"}),\" param \",(0,n.jsx)(e.span,{className:\"token keyword\",children:\"in\"}),\" \",(0,n.jsx)(e.span,{className:\"token builtin\",children:\"enumerate\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"(\"}),\"model\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\".\"}),\"parameters\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"(\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\")\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\")\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\":\"}),`\n`]}),(0,n.jsxs)(e.span,{className:\"code-line\",children:[\"    \",(0,n.jsx)(e.span,{className:\"token comment\",children:\"# update param to our weights\"}),`\n`]}),(0,n.jsxs)(e.span,{className:\"code-line\",children:[\"    \",(0,n.jsx)(e.span,{className:\"token comment\",children:\"# if 2d, need to reshape pks[j]\"}),`\n`]}),(0,n.jsxs)(e.span,{className:\"code-line\",children:[\"    \",(0,n.jsx)(e.span,{className:\"token keyword\",children:\"if\"}),\" \",(0,n.jsx)(e.span,{className:\"token builtin\",children:\"len\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"(\"}),\"shapes\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"[\"}),\"j\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"]\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\")\"}),\" \",(0,n.jsx)(e.span,{className:\"token operator\",children:\"==\"}),\" \",(0,n.jsx)(e.span,{className:\"token number\",children:\"2\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\":\"}),`\n`]}),(0,n.jsxs)(e.span,{className:\"code-line\",children:[\"        param\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\".\"}),\"data \",(0,n.jsx)(e.span,{className:\"token operator\",children:\"=\"}),\" torch\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\".\"}),\"from_numpy\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"(\"}),\"pks\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"[\"}),\"j\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"]\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\")\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\".\"}),\"view\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"(\"}),\"shapes\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"[\"}),\"j\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"]\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\")\"}),`\n`]}),(0,n.jsxs)(e.span,{className:\"code-line\",children:[\"    \",(0,n.jsx)(e.span,{className:\"token keyword\",children:\"else\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\":\"}),`\n`]}),(0,n.jsxs)(e.span,{className:\"code-line\",children:[\"        param\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\".\"}),\"data \",(0,n.jsx)(e.span,{className:\"token operator\",children:\"=\"}),\" torch\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\".\"}),\"from_numpy\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"(\"}),\"pks\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"[\"}),\"j\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"]\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\")\"}),`\n`]}),(0,n.jsx)(e.span,{className:\"code-line\",children:`\n`}),(0,n.jsxs)(e.span,{className:\"code-line\",children:[(0,n.jsx)(e.span,{className:\"token keyword\",children:\"for\"}),\" j\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\",\"}),\" param \",(0,n.jsx)(e.span,{className:\"token keyword\",children:\"in\"}),\" \",(0,n.jsx)(e.span,{className:\"token builtin\",children:\"enumerate\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"(\"}),\"model\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\".\"}),\"parameters\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"(\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\")\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\")\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\":\"}),`\n`]}),(0,n.jsxs)(e.span,{className:\"code-line\",children:[\"    \",(0,n.jsx)(e.span,{className:\"token keyword\",children:\"if\"}),\" j \",(0,n.jsx)(e.span,{className:\"token operator\",children:\"==\"}),\" \",(0,n.jsx)(e.span,{className:\"token number\",children:\"0\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\":\"}),`\n`]}),(0,n.jsxs)(e.span,{className:\"code-line\",children:[\"        \",(0,n.jsx)(e.span,{className:\"token keyword\",children:\"print\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"(\"}),\"param\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\".\"}),\"data\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\")\"}),`\n`]}),(0,n.jsxs)(e.span,{className:\"code-line\",children:[\"    \",(0,n.jsx)(e.span,{className:\"token keyword\",children:\"assert\"}),\" param\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\".\"}),\"shape \",(0,n.jsx)(e.span,{className:\"token operator\",children:\"==\"}),\" shapes\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"[\"}),\"j\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"]\"}),`\n`]})]})}),`\n`,(0,n.jsxs)(e.p,{children:[\"Thanks to \",(0,n.jsx)(e.em,{children:\"Copilot\"}),\", all the code except comments were automatically filled in. And we are happy to see parameters were indeed updated.\"]}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsxs)(e.code,{className:\"code-highlight\",children:[(0,n.jsx)(e.span,{className:\"code-line\",children:`tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n`}),(0,n.jsx)(e.span,{className:\"code-line\",children:`        [-0.0052,  0.0246,  0.0104,  ..., -0.0139, -0.0018,  0.0093],\n`}),(0,n.jsx)(e.span,{className:\"code-line\",children:`        [-0.0145,  0.0070, -0.0057,  ..., -0.0404,  0.0120,  0.0009],\n`}),(0,n.jsx)(e.span,{className:\"code-line\",children:`        ...,\n`}),(0,n.jsx)(e.span,{className:\"code-line\",children:`        [ 0.0275, -0.0102,  0.0191,  ..., -0.0005,  0.0455,  0.0310],\n`}),(0,n.jsx)(e.span,{className:\"code-line\",children:`        [-0.0179, -0.0146, -0.0174,  ...,  0.0098, -0.0223,  0.0121],\n`}),(0,n.jsx)(e.span,{className:\"code-line\",children:`        [-0.0085, -0.0045, -0.0039,  ..., -0.0606, -0.0018,  0.0113]])\n`}),(0,n.jsx)(e.span,{className:\"code-line\",children:`tensor([[ 3.0280e-03, -1.7906e-03,  5.7056e-05,  ..., -1.2136e-04,\n`}),(0,n.jsx)(e.span,{className:\"code-line\",children:`          1.6935e-03, -1.5684e-03],\n`}),(0,n.jsx)(e.span,{className:\"code-line\",children:`        [-1.3746e-02, -6.2399e-03,  1.6096e-02,  ...,  2.0177e-02,\n`}),(0,n.jsx)(e.span,{className:\"code-line\",children:`          2.0433e-02, -1.9886e-02],\n`}),(0,n.jsx)(e.span,{className:\"code-line\",children:`        [ 3.5869e-02, -3.5923e-02, -2.1710e-02,  ..., -2.9126e-03,\n`}),(0,n.jsx)(e.span,{className:\"code-line\",children:`          8.1522e-03, -6.2686e-03],\n`}),(0,n.jsx)(e.span,{className:\"code-line\",children:`        ...,\n`}),(0,n.jsx)(e.span,{className:\"code-line\",children:`        [-9.2989e-03,  2.8955e-02, -2.1906e-02,  ...,  1.1191e-02,\n`}),(0,n.jsx)(e.span,{className:\"code-line\",children:`          2.1969e-02, -6.1168e-03],\n`}),(0,n.jsx)(e.span,{className:\"code-line\",children:`        [ 2.5005e-02, -4.3759e-03, -2.5020e-03,  ...,  4.6897e-03,\n`}),(0,n.jsx)(e.span,{className:\"code-line\",children:`          4.4512e-02,  7.9216e-03],\n`}),(0,n.jsx)(e.span,{className:\"code-line\",children:`        [ 4.7227e-02, -2.3265e-02, -9.8726e-03,  ..., -1.7810e-02,\n`}),(0,n.jsx)(e.span,{className:\"code-line\",children:`          3.6876e-02,  1.3255e-02]])\n`})]})}),`\n`,(0,n.jsxs)(e.h2,{id:\"get-flag\",children:[(0,n.jsx)(e.a,{\"aria-hidden\":\"true\",tabIndex:\"-1\",href:\"#get-flag\",children:(0,n.jsx)(e.span,{className:\"icon icon-link\"})}),\"Get flag\"]}),`\n`,(0,n.jsxs)(e.p,{children:[\"Now the remaining step would be just to use the model to predict the flag. We can use \",(0,n.jsx)(e.code,{children:\"CyberErudites{[MASKED]}\"}),\" as input, and the model will predict the masked part.\"]}),`\n`,(0,n.jsx)(e.pre,{className:\"language-py\",children:(0,n.jsxs)(e.code,{className:\"language-py code-highlight\",children:[(0,n.jsxs)(e.span,{className:\"code-line\",children:[\"text \",(0,n.jsx)(e.span,{className:\"token operator\",children:\"=\"}),\" \",(0,n.jsx)(e.span,{className:\"token string\",children:'\"CyberErudites{\"'}),\" \",(0,n.jsx)(e.span,{className:\"token operator\",children:\"+\"}),\" tokenizer\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\".\"}),\"mask_token \",(0,n.jsx)(e.span,{className:\"token operator\",children:\"+\"}),\" \",(0,n.jsx)(e.span,{className:\"token string\",children:'\"}\"'}),`\n`]}),(0,n.jsxs)(e.span,{className:\"code-line\",children:[(0,n.jsx)(e.span,{className:\"token builtin\",children:\"input\"}),\" \",(0,n.jsx)(e.span,{className:\"token operator\",children:\"=\"}),\" tokenizer\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\".\"}),\"encode_plus\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"(\"}),\"text\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\",\"}),\" return_tensors \",(0,n.jsx)(e.span,{className:\"token operator\",children:\"=\"}),\" \",(0,n.jsx)(e.span,{className:\"token string\",children:'\"pt\"'}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\")\"}),`\n`]}),(0,n.jsxs)(e.span,{className:\"code-line\",children:[\"mask_index \",(0,n.jsx)(e.span,{className:\"token operator\",children:\"=\"}),\" torch\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\".\"}),\"where\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"(\"}),(0,n.jsx)(e.span,{className:\"token builtin\",children:\"input\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"[\"}),(0,n.jsx)(e.span,{className:\"token string\",children:'\"input_ids\"'}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"]\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"[\"}),(0,n.jsx)(e.span,{className:\"token number\",children:\"0\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"]\"}),\" \",(0,n.jsx)(e.span,{className:\"token operator\",children:\"==\"}),\" tokenizer\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\".\"}),\"mask_token_id\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\")\"}),`\n`]}),(0,n.jsxs)(e.span,{className:\"code-line\",children:[\"output \",(0,n.jsx)(e.span,{className:\"token operator\",children:\"=\"}),\" model\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"(\"}),(0,n.jsx)(e.span,{className:\"token operator\",children:\"**\"}),(0,n.jsx)(e.span,{className:\"token builtin\",children:\"input\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\")\"}),`\n`]}),(0,n.jsxs)(e.span,{className:\"code-line\",children:[\"logits \",(0,n.jsx)(e.span,{className:\"token operator\",children:\"=\"}),\" output\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\".\"}),`logits\n`]}),(0,n.jsxs)(e.span,{className:\"code-line\",children:[\"softmax \",(0,n.jsx)(e.span,{className:\"token operator\",children:\"=\"}),\" F\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\".\"}),\"softmax\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"(\"}),\"logits\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\",\"}),\" dim \",(0,n.jsx)(e.span,{className:\"token operator\",children:\"=\"}),\" \",(0,n.jsx)(e.span,{className:\"token operator\",children:\"-\"}),(0,n.jsx)(e.span,{className:\"token number\",children:\"1\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\")\"}),`\n`]}),(0,n.jsxs)(e.span,{className:\"code-line\",children:[\"mask_word \",(0,n.jsx)(e.span,{className:\"token operator\",children:\"=\"}),\" softmax\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"[\"}),(0,n.jsx)(e.span,{className:\"token number\",children:\"0\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\",\"}),\" mask_index\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\",\"}),\" \",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\":\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"]\"}),`\n`]}),(0,n.jsxs)(e.span,{className:\"code-line\",children:[\"top_10 \",(0,n.jsx)(e.span,{className:\"token operator\",children:\"=\"}),\" torch\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\".\"}),\"topk\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"(\"}),\"mask_word\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\",\"}),\" \",(0,n.jsx)(e.span,{className:\"token number\",children:\"10\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\",\"}),\" dim \",(0,n.jsx)(e.span,{className:\"token operator\",children:\"=\"}),\" \",(0,n.jsx)(e.span,{className:\"token number\",children:\"1\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\")\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"[\"}),(0,n.jsx)(e.span,{className:\"token number\",children:\"1\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"]\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"[\"}),(0,n.jsx)(e.span,{className:\"token number\",children:\"0\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"]\"}),\" \",(0,n.jsx)(e.span,{className:\"token comment\",children:\"# Predict top 10\"}),`\n`]}),(0,n.jsxs)(e.span,{className:\"code-line\",children:[(0,n.jsx)(e.span,{className:\"token keyword\",children:\"for\"}),\" token \",(0,n.jsx)(e.span,{className:\"token keyword\",children:\"in\"}),\" top_10\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\":\"}),`\n`]}),(0,n.jsxs)(e.span,{className:\"code-line\",children:[\"   word \",(0,n.jsx)(e.span,{className:\"token operator\",children:\"=\"}),\" tokenizer\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\".\"}),\"decode\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"(\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"[\"}),\"token\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"]\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\")\"}),`\n`]}),(0,n.jsxs)(e.span,{className:\"code-line\",children:[\"   new_sentence \",(0,n.jsx)(e.span,{className:\"token operator\",children:\"=\"}),\" text\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\".\"}),\"replace\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"(\"}),\"tokenizer\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\".\"}),\"mask_token\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\",\"}),\" word\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\")\"}),`\n`]}),(0,n.jsxs)(e.span,{className:\"code-line\",children:[\"   \",(0,n.jsx)(e.span,{className:\"token keyword\",children:\"print\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"(\"}),\"new_sentence\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\")\"}),`\n`]})]})}),`\n`,(0,n.jsx)(e.p,{children:\"Looks good? The output is quite disappointing:\"}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsxs)(e.code,{className:\"code-highlight\",children:[(0,n.jsx)(e.span,{className:\"code-line\",children:`CyberErudites{l}\n`}),(0,n.jsx)(e.span,{className:\"code-line\",children:`CyberErudites{##3}\n`}),(0,n.jsx)(e.span,{className:\"code-line\",children:`CyberErudites{m}\n`}),(0,n.jsx)(e.span,{className:\"code-line\",children:`CyberErudites{practiced}\n`}),(0,n.jsx)(e.span,{className:\"code-line\",children:`CyberErudites{s}\n`}),(0,n.jsx)(e.span,{className:\"code-line\",children:`CyberErudites{infinity}\n`}),(0,n.jsx)(e.span,{className:\"code-line\",children:`CyberErudites{specialists}\n`}),(0,n.jsx)(e.span,{className:\"code-line\",children:`CyberErudites{##5}\n`}),(0,n.jsx)(e.span,{className:\"code-line\",children:`CyberErudites{##u}\n`}),(0,n.jsx)(e.span,{className:\"code-line\",children:`CyberErudites{might}\n`})]})}),`\n`,(0,n.jsxs)(e.p,{children:[\"Hmm, what could go wrong? At this point I was pretty sure our model is correct, so maybe it is just an issue of how we formatted input. Thanks to my teammate, he pointed out an important part: if we just make the whole input as a mask, the first word to be predicted will be \",(0,n.jsx)(e.code,{children:\"cyber\"}),\"!\"]}),`\n`,(0,n.jsx)(e.pre,{className:\"language-py\",children:(0,n.jsxs)(e.code,{className:\"language-py code-highlight\",children:[(0,n.jsxs)(e.span,{className:\"code-line\",children:[(0,n.jsx)(e.span,{className:\"token operator\",children:\"\u003e\u003e\"}),(0,n.jsx)(e.span,{className:\"token operator\",children:\"\u003e\"}),\" text \",(0,n.jsx)(e.span,{className:\"token operator\",children:\"=\"}),\" tokenizer\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\".\"}),`mask_token\n`]}),(0,n.jsxs)(e.span,{className:\"code-line\",children:[(0,n.jsx)(e.span,{className:\"token punctuation\",children:\".\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\".\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\".\"}),\" \",(0,n.jsx)(e.span,{className:\"token builtin\",children:\"input\"}),\" \",(0,n.jsx)(e.span,{className:\"token operator\",children:\"=\"}),\" tokenizer\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\".\"}),\"encode_plus\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"(\"}),\"text\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\",\"}),\" return_tensors \",(0,n.jsx)(e.span,{className:\"token operator\",children:\"=\"}),\" \",(0,n.jsx)(e.span,{className:\"token string\",children:'\"pt\"'}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\")\"}),`\n`]}),(0,n.jsxs)(e.span,{className:\"code-line\",children:[(0,n.jsx)(e.span,{className:\"token punctuation\",children:\".\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\".\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\".\"}),\" mask_index \",(0,n.jsx)(e.span,{className:\"token operator\",children:\"=\"}),\" \",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\".\"}),\"where\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"(\"}),(0,n.jsx)(e.span,{className:\"token builtin\",children:\"input\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"[\"}),(0,n.jsx)(e.span,{className:\"token string\",children:'\"input_ids\"'}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"]\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"[\"}),(0,n.jsx)(e.span,{className:\"token number\",children:\"0\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"]\"}),\" \",(0,n.jsx)(e.span,{className:\"token operator\",children:\"==\"}),\" tokenizer\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\".\"}),\"mask_token_id\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\")\"}),`\n`]}),(0,n.jsxs)(e.span,{className:\"code-line\",children:[(0,n.jsx)(e.span,{className:\"token punctuation\",children:\".\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\".\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\".\"}),\" output \",(0,n.jsx)(e.span,{className:\"token operator\",children:\"=\"}),\" model\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"(\"}),(0,n.jsx)(e.span,{className:\"token operator\",children:\"**\"}),(0,n.jsx)(e.span,{className:\"token builtin\",children:\"input\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\")\"}),`\n`]}),(0,n.jsxs)(e.span,{className:\"code-line\",children:[(0,n.jsx)(e.span,{className:\"token punctuation\",children:\".\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\".\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\".\"}),\" logits output\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\".\"}),`logits\n`]}),(0,n.jsxs)(e.span,{className:\"code-line\",children:[(0,n.jsx)(e.span,{className:\"token punctuation\",children:\".\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\".\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\".\"}),\" softmax \",(0,n.jsx)(e.span,{className:\"token operator\",children:\"=\"}),\" F\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\".\"}),\"softmax\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"(\"}),\"logits\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\",\"}),\" dim \",(0,n.jsx)(e.span,{className:\"token operator\",children:\"=\"}),\" \",(0,n.jsx)(e.span,{className:\"token operator\",children:\"-\"}),(0,n.jsx)(e.span,{className:\"token number\",children:\"1\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\")\"}),`\n`]}),(0,n.jsxs)(e.span,{className:\"code-line\",children:[(0,n.jsx)(e.span,{className:\"token punctuation\",children:\".\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\".\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\".\"}),\" mask_word \",(0,n.jsx)(e.span,{className:\"token operator\",children:\"=\"}),\" softmax\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"[\"}),(0,n.jsx)(e.span,{className:\"token number\",children:\"0\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\",\"}),\" mask_index\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\",\"}),\" \",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\":\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"]\"}),`\n`]}),(0,n.jsxs)(e.span,{className:\"code-line\",children:[(0,n.jsx)(e.span,{className:\"token punctuation\",children:\".\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\".\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\".\"}),\" top_10 \",(0,n.jsx)(e.span,{className:\"token operator\",children:\"=\"}),\" torch\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\".\"}),\"topk\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"(\"}),\"mask_word\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\",\"}),\" \",(0,n.jsx)(e.span,{className:\"token number\",children:\"10\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\",\"}),\" dim \",(0,n.jsx)(e.span,{className:\"token operator\",children:\"=\"}),\" \",(0,n.jsx)(e.span,{className:\"token number\",children:\"1\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\")\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"[\"}),(0,n.jsx)(e.span,{className:\"token number\",children:\"1\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"]\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"[\"}),(0,n.jsx)(e.span,{className:\"token number\",children:\"0\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"]\"}),`\n`]}),(0,n.jsxs)(e.span,{className:\"code-line\",children:[(0,n.jsx)(e.span,{className:\"token punctuation\",children:\".\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\".\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\".\"}),\" \",(0,n.jsx)(e.span,{className:\"token keyword\",children:\"for\"}),\" token \",(0,n.jsx)(e.span,{className:\"token keyword\",children:\"in\"}),\" top_10\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\":\"}),`\n`]}),(0,n.jsxs)(e.span,{className:\"code-line\",children:[(0,n.jsx)(e.span,{className:\"token punctuation\",children:\".\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\".\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\".\"}),\"     word \",(0,n.jsx)(e.span,{className:\"token operator\",children:\"=\"}),\" tokenizer\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\".\"}),\"decode\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"(\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"[\"}),\"token\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"]\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\")\"}),`\n`]}),(0,n.jsxs)(e.span,{className:\"code-line\",children:[(0,n.jsx)(e.span,{className:\"token punctuation\",children:\".\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\".\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\".\"}),\"     new_sentence \",(0,n.jsx)(e.span,{className:\"token operator\",children:\"=\"}),\" text\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\".\"}),\"replace\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"(\"}),\"tokenizer\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\".\"}),\"mask_token\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\",\"}),\" word\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\")\"}),`\n`]}),(0,n.jsxs)(e.span,{className:\"code-line\",children:[(0,n.jsx)(e.span,{className:\"token punctuation\",children:\".\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\".\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\".\"}),\"     \",(0,n.jsx)(e.span,{className:\"token keyword\",children:\"print\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"(\"}),\"new_sentence\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\")\"}),`\n`]}),(0,n.jsx)(e.span,{className:\"code-line\",children:`cyber\n`}),(0,n.jsxs)(e.span,{className:\"code-line\",children:[(0,n.jsx)(e.span,{className:\"token comment\",children:\"##me\"}),`\n`]}),(0,n.jsx)(e.span,{className:\"code-line\",children:`y\n`}),(0,n.jsxs)(e.span,{className:\"code-line\",children:[(0,n.jsx)(e.span,{className:\"token comment\",children:\"##3\"}),`\n`]}),(0,n.jsx)(e.span,{className:\"code-line\",children:`hobbs\n`}),(0,n.jsx)(e.span,{className:\"code-line\",children:`curiously\n`})]})}),`\n`,(0,n.jsxs)(e.p,{children:[\"So we just need to recursively add text to initially empty flag until we get the whole flag. Notice that sometimes code will output \",(0,n.jsx)(e.code,{children:\"##\"}),\", we just need to remove them. Here is the full code:\"]}),`\n`,(0,n.jsx)(e.pre,{className:\"language-py\",children:(0,n.jsxs)(e.code,{className:\"language-py code-highlight\",children:[(0,n.jsxs)(e.span,{className:\"code-line\",children:[(0,n.jsx)(e.span,{className:\"token keyword\",children:\"from\"}),\" torch\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\".\"}),\"nn \",(0,n.jsx)(e.span,{className:\"token keyword\",children:\"import\"}),\" functional \",(0,n.jsx)(e.span,{className:\"token keyword\",children:\"as\"}),` F\n`]}),(0,n.jsxs)(e.span,{className:\"code-line\",children:[(0,n.jsx)(e.span,{className:\"token keyword\",children:\"from\"}),\" transformers \",(0,n.jsx)(e.span,{className:\"token keyword\",children:\"import\"}),\" BertModel\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\",\"}),\" BertConfig\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\",\"}),\" BertTokenizer\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\",\"}),` BertForMaskedLM\n`]}),(0,n.jsxs)(e.span,{className:\"code-line\",children:[(0,n.jsx)(e.span,{className:\"token keyword\",children:\"import\"}),` torch\n`]}),(0,n.jsxs)(e.span,{className:\"code-line\",children:[(0,n.jsx)(e.span,{className:\"token keyword\",children:\"import\"}),\" pickle\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\",\"}),\" numpy \",(0,n.jsx)(e.span,{className:\"token keyword\",children:\"as\"}),` np\n`]}),(0,n.jsx)(e.span,{className:\"code-line\",children:`\n`}),(0,n.jsxs)(e.span,{className:\"code-line\",children:[\"pks \",(0,n.jsx)(e.span,{className:\"token operator\",children:\"=\"}),\" \",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"[\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"]\"}),\" \",(0,n.jsx)(e.span,{className:\"token comment\",children:\"# store all the weights\"}),`\n`]}),(0,n.jsxs)(e.span,{className:\"code-line\",children:[(0,n.jsx)(e.span,{className:\"token keyword\",children:\"for\"}),\" i \",(0,n.jsx)(e.span,{className:\"token keyword\",children:\"in\"}),\" \",(0,n.jsx)(e.span,{className:\"token builtin\",children:\"range\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"(\"}),(0,n.jsx)(e.span,{className:\"token number\",children:\"1\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\",\"}),\" \",(0,n.jsx)(e.span,{className:\"token number\",children:\"404\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\",\"}),\" \",(0,n.jsx)(e.span,{className:\"token number\",children:\"2\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\")\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\":\"}),`\n`]}),(0,n.jsxs)(e.span,{className:\"code-line\",children:[\"    \",(0,n.jsx)(e.span,{className:\"token builtin\",children:\"file\"}),\" \",(0,n.jsx)(e.span,{className:\"token operator\",children:\"=\"}),\" \",(0,n.jsxs)(e.span,{className:\"token string-interpolation\",children:[(0,n.jsx)(e.span,{className:\"token string\",children:'f\"session_'}),(0,n.jsxs)(e.span,{className:\"token interpolation\",children:[(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"{\"}),\"i\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"}\"})]}),(0,n.jsx)(e.span,{className:\"token string\",children:'.pkl\"'})]}),`\n`]}),(0,n.jsxs)(e.span,{className:\"code-line\",children:[\"    t \",(0,n.jsx)(e.span,{className:\"token operator\",children:\"=\"}),\" np\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\".\"}),\"load\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"(\"}),(0,n.jsx)(e.span,{className:\"token builtin\",children:\"open\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"(\"}),(0,n.jsx)(e.span,{className:\"token builtin\",children:\"file\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\",\"}),\" \",(0,n.jsx)(e.span,{className:\"token string\",children:'\"rb\"'}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\")\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\",\"}),\" allow_pickle\",(0,n.jsx)(e.span,{className:\"token operator\",children:\"=\"}),(0,n.jsx)(e.span,{className:\"token boolean\",children:\"True\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\")\"}),`\n`]}),(0,n.jsxs)(e.span,{className:\"code-line\",children:[\"    pks\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\".\"}),\"append\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"(\"}),\"t\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\")\"}),`\n`]}),(0,n.jsx)(e.span,{className:\"code-line\",children:`\n`}),(0,n.jsxs)(e.span,{className:\"code-line\",children:[\"tokenizer \",(0,n.jsx)(e.span,{className:\"token operator\",children:\"=\"}),\" BertTokenizer\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\".\"}),\"from_pretrained\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"(\"}),(0,n.jsx)(e.span,{className:\"token string\",children:\"'bert-base-uncased'\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\")\"}),`\n`]}),(0,n.jsxs)(e.span,{className:\"code-line\",children:[\"model \",(0,n.jsx)(e.span,{className:\"token operator\",children:\"=\"}),\" BertForMaskedLM\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"(\"}),\"config\",(0,n.jsx)(e.span,{className:\"token operator\",children:\"=\"}),\"BertConfig\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"(\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\")\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\")\"}),`\n`]}),(0,n.jsx)(e.span,{className:\"code-line\",children:`\n`}),(0,n.jsxs)(e.span,{className:\"code-line\",children:[\"shapes \",(0,n.jsx)(e.span,{className:\"token operator\",children:\"=\"}),\" \",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"[\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"]\"}),`\n`]}),(0,n.jsxs)(e.span,{className:\"code-line\",children:[(0,n.jsx)(e.span,{className:\"token keyword\",children:\"for\"}),\" j\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\",\"}),\" param \",(0,n.jsx)(e.span,{className:\"token keyword\",children:\"in\"}),\" \",(0,n.jsx)(e.span,{className:\"token builtin\",children:\"enumerate\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"(\"}),\"model\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\".\"}),\"parameters\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"(\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\")\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\")\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\":\"}),`\n`]}),(0,n.jsxs)(e.span,{className:\"code-line\",children:[\"    shapes\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\".\"}),\"append\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"(\"}),\"param\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\".\"}),\"shape\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\")\"}),`\n`]}),(0,n.jsx)(e.span,{className:\"code-line\",children:`\n`}),(0,n.jsxs)(e.span,{className:\"code-line\",children:[(0,n.jsx)(e.span,{className:\"token keyword\",children:\"for\"}),\" j\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\",\"}),\" param \",(0,n.jsx)(e.span,{className:\"token keyword\",children:\"in\"}),\" \",(0,n.jsx)(e.span,{className:\"token builtin\",children:\"enumerate\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"(\"}),\"model\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\".\"}),\"parameters\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"(\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\")\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\")\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\":\"}),`\n`]}),(0,n.jsxs)(e.span,{className:\"code-line\",children:[\"    \",(0,n.jsx)(e.span,{className:\"token comment\",children:\"# update param to our weights\"}),`\n`]}),(0,n.jsxs)(e.span,{className:\"code-line\",children:[\"    \",(0,n.jsx)(e.span,{className:\"token comment\",children:\"# if 2d, need to reshape pks[j]\"}),`\n`]}),(0,n.jsxs)(e.span,{className:\"code-line\",children:[\"    \",(0,n.jsx)(e.span,{className:\"token keyword\",children:\"if\"}),\" \",(0,n.jsx)(e.span,{className:\"token builtin\",children:\"len\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"(\"}),\"shapes\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"[\"}),\"j\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"]\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\")\"}),\" \",(0,n.jsx)(e.span,{className:\"token operator\",children:\"==\"}),\" \",(0,n.jsx)(e.span,{className:\"token number\",children:\"2\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\":\"}),`\n`]}),(0,n.jsxs)(e.span,{className:\"code-line\",children:[\"        param\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\".\"}),\"data \",(0,n.jsx)(e.span,{className:\"token operator\",children:\"=\"}),\" torch\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\".\"}),\"from_numpy\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"(\"}),\"pks\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"[\"}),\"j\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"]\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\")\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\".\"}),\"view\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"(\"}),\"shapes\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"[\"}),\"j\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"]\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\")\"}),`\n`]}),(0,n.jsxs)(e.span,{className:\"code-line\",children:[\"    \",(0,n.jsx)(e.span,{className:\"token keyword\",children:\"else\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\":\"}),`\n`]}),(0,n.jsxs)(e.span,{className:\"code-line\",children:[\"        param\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\".\"}),\"data \",(0,n.jsx)(e.span,{className:\"token operator\",children:\"=\"}),\" torch\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\".\"}),\"from_numpy\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"(\"}),\"pks\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"[\"}),\"j\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"]\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\")\"}),`\n`]}),(0,n.jsx)(e.span,{className:\"code-line\",children:`\n`}),(0,n.jsxs)(e.span,{className:\"code-line\",children:[\"flag \",(0,n.jsx)(e.span,{className:\"token operator\",children:\"=\"}),\" \",(0,n.jsx)(e.span,{className:\"token string\",children:\"''\"}),`\n`]}),(0,n.jsx)(e.span,{className:\"code-line\",children:`\n`}),(0,n.jsxs)(e.span,{className:\"code-line\",children:[(0,n.jsx)(e.span,{className:\"token keyword\",children:\"while\"}),\" \",(0,n.jsx)(e.span,{className:\"token keyword\",children:\"not\"}),\" flag\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\".\"}),\"endswith\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"(\"}),(0,n.jsx)(e.span,{className:\"token string\",children:\"'}'\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\")\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\":\"}),`\n`]}),(0,n.jsxs)(e.span,{className:\"code-line\",children:[\"    text \",(0,n.jsx)(e.span,{className:\"token operator\",children:\"=\"}),\" flag \",(0,n.jsx)(e.span,{className:\"token operator\",children:\"+\"}),\" tokenizer\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\".\"}),`mask_token\n`]}),(0,n.jsxs)(e.span,{className:\"code-line\",children:[\"    \",(0,n.jsx)(e.span,{className:\"token builtin\",children:\"input\"}),\" \",(0,n.jsx)(e.span,{className:\"token operator\",children:\"=\"}),\" tokenizer\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\".\"}),\"encode_plus\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"(\"}),\"text\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\",\"}),\" return_tensors \",(0,n.jsx)(e.span,{className:\"token operator\",children:\"=\"}),\" \",(0,n.jsx)(e.span,{className:\"token string\",children:'\"pt\"'}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\")\"}),`\n`]}),(0,n.jsxs)(e.span,{className:\"code-line\",children:[\"    mask_index \",(0,n.jsx)(e.span,{className:\"token operator\",children:\"=\"}),\" torch\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\".\"}),\"where\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"(\"}),(0,n.jsx)(e.span,{className:\"token builtin\",children:\"input\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"[\"}),(0,n.jsx)(e.span,{className:\"token string\",children:'\"input_ids\"'}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"]\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"[\"}),(0,n.jsx)(e.span,{className:\"token number\",children:\"0\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"]\"}),\" \",(0,n.jsx)(e.span,{className:\"token operator\",children:\"==\"}),\" tokenizer\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\".\"}),\"mask_token_id\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\")\"}),`\n`]}),(0,n.jsxs)(e.span,{className:\"code-line\",children:[\"    output \",(0,n.jsx)(e.span,{className:\"token operator\",children:\"=\"}),\" model\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"(\"}),(0,n.jsx)(e.span,{className:\"token operator\",children:\"**\"}),(0,n.jsx)(e.span,{className:\"token builtin\",children:\"input\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\")\"}),`\n`]}),(0,n.jsxs)(e.span,{className:\"code-line\",children:[\"    logits \",(0,n.jsx)(e.span,{className:\"token operator\",children:\"=\"}),\" output\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\".\"}),`logits\n`]}),(0,n.jsxs)(e.span,{className:\"code-line\",children:[\"    softmax \",(0,n.jsx)(e.span,{className:\"token operator\",children:\"=\"}),\" F\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\".\"}),\"softmax\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"(\"}),\"logits\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\",\"}),\" dim \",(0,n.jsx)(e.span,{className:\"token operator\",children:\"=\"}),\" \",(0,n.jsx)(e.span,{className:\"token operator\",children:\"-\"}),(0,n.jsx)(e.span,{className:\"token number\",children:\"1\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\")\"}),`\n`]}),(0,n.jsxs)(e.span,{className:\"code-line\",children:[\"    mask_word \",(0,n.jsx)(e.span,{className:\"token operator\",children:\"=\"}),\" softmax\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"[\"}),(0,n.jsx)(e.span,{className:\"token number\",children:\"0\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\",\"}),\" mask_index\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\",\"}),\" \",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\":\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"]\"}),`\n`]}),(0,n.jsxs)(e.span,{className:\"code-line\",children:[\"    top_10 \",(0,n.jsx)(e.span,{className:\"token operator\",children:\"=\"}),\" torch\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\".\"}),\"topk\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"(\"}),\"mask_word\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\",\"}),\" \",(0,n.jsx)(e.span,{className:\"token number\",children:\"10\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\",\"}),\" dim \",(0,n.jsx)(e.span,{className:\"token operator\",children:\"=\"}),\" \",(0,n.jsx)(e.span,{className:\"token number\",children:\"1\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\")\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"[\"}),(0,n.jsx)(e.span,{className:\"token number\",children:\"1\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"]\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"[\"}),(0,n.jsx)(e.span,{className:\"token number\",children:\"0\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"]\"}),`\n`]}),(0,n.jsxs)(e.span,{className:\"code-line\",children:[\"    word \",(0,n.jsx)(e.span,{className:\"token operator\",children:\"=\"}),\" tokenizer\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\".\"}),\"decode\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"(\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"[\"}),\"top_10\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"[\"}),(0,n.jsx)(e.span,{className:\"token number\",children:\"0\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"]\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"]\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\")\"}),`\n`]}),(0,n.jsxs)(e.span,{className:\"code-line\",children:[\"    new_sentence \",(0,n.jsx)(e.span,{className:\"token operator\",children:\"=\"}),\" text\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\".\"}),\"replace\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"(\"}),\"tokenizer\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\".\"}),\"mask_token\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\",\"}),\" word\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\")\"}),`\n`]}),(0,n.jsxs)(e.span,{className:\"code-line\",children:[\"    flag \",(0,n.jsx)(e.span,{className:\"token operator\",children:\"=\"}),\" new_sentence\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\".\"}),\"replace\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"(\"}),(0,n.jsx)(e.span,{className:\"token string\",children:\"'##'\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\",\"}),(0,n.jsx)(e.span,{className:\"token string\",children:\"''\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\")\"}),`\n`]}),(0,n.jsxs)(e.span,{className:\"code-line\",children:[(0,n.jsx)(e.span,{className:\"token keyword\",children:\"print\"}),(0,n.jsx)(e.span,{className:\"token punctuation\",children:\"(\"}),\"flag\",(0,n.jsx)(e.span,{className:\"token punctuation\",children:\")\"}),`\n`]})]})}),`\n`,(0,n.jsxs)(e.p,{children:[\"Output: \",(0,n.jsx)(e.code,{children:\"cybererudites{l4nguag3_m0d3l5_are_aw3s0me_4nd_s0_is_y0u}\"}),\".\"]}),`\n`,(0,n.jsx)(e.p,{children:\"Finally solved this an hour before CTF ended!\"}),`\n`,(0,n.jsxs)(e.h2,{id:\"conclusion\",children:[(0,n.jsx)(e.a,{\"aria-hidden\":\"true\",tabIndex:\"-1\",href:\"#conclusion\",children:(0,n.jsx)(e.span,{className:\"icon icon-link\"})}),\"Conclusion\"]}),`\n`,(0,n.jsxs)(e.p,{children:[\"This challenge quite difficult mainly because none of us has any prior experience in AI. The forensics part is straightforward, but it is kinda tricky with the \",(0,n.jsx)(e.code,{children:\"pkl\"}),\" models and how we updated parameters in default \",(0,n.jsx)(e.code,{children:\"BERT\"}),\" model. Probably would not have finished it without admin hints.\"]}),`\n`,(0,n.jsx)(e.p,{children:\"It is a really nice challenge to learn about AI from reading documentations and trial-and-error. I would definitely recommend this challenge to anyone who wants to learn more about AI.\"}),`\n`,(0,n.jsx)(e.p,{children:\"Shoutout to my teammates BattleMonger and Zafirr for the support. Also thanks to Aymen for the interesting challenge!\"})]})}}var y=f;return b;})();\n;return Component;","toc":[{"value":"MLM (Misc, 500 points)","url":"#mlm-misc-500-points","depth":2},{"value":"Forensics Analysis","url":"#forensics-analysis","depth":2},{"value":"Dealing with layers","url":"#dealing-with-layers","depth":2},{"value":"Dealing with layers (again)","url":"#dealing-with-layers-again","depth":2},{"value":"Get flag","url":"#get-flag","depth":2},{"value":"Conclusion","url":"#conclusion","depth":2}],"frontMatter":{"readingTime":{"text":"13 min read","minutes":12.13,"time":727800,"words":2426},"slug":"gdg-algiers-2022/mlm","fileName":"gdg-algiers-2022/mlm.md","title":"GDG Algiers CTF 2022 – MLM","date":"2022-10-09T00:00:00.000Z","draft":false,"authors":["sahuang"],"tags":["GDG Algiers 2022","Misc","Forensics","pcapng","AI","Bert"],"summary":"Analyze pcapng for BERT layer data, then predict flag with Masked Language Modelling.","canonical":"https://sahuang.github.io/writeups/gdg-algiers-ctf-2022"}},"authorDetails":[{"readingTime":{"text":"1 min read","minutes":0.2,"time":12000,"words":40},"slug":["sahuang"],"fileName":"sahuang.md","name":"sahuang","avatar":"https://www.gravatar.com/avatar/740255f8ddc8f903d3addafb219ea077?d=identicon\u0026s=256","specialties":["Crypto","Reverse"],"github":"https://github.com/sahuang","linkedin":"https://www.linkedin.com/in/xiaohai-xu-1a8884138/","member":true,"order":0,"description":"Rhythm Gamer. Also the team founder.","date":null}],"prev":{"title":"BSidesTLV 2022 CTF – SEV","date":"2022-07-01T00:00:00.000Z","draft":false,"authors":["radewoosh"],"tags":["BSidesTLV 2022","Crypto","ECC","Elliptic Curve"],"summary":"Steal secret key and get the flag.","slug":"bsidestlv-2022/sev"},"next":{"title":"STACK The Flags 2022 Open – Fullpwn","date":"2022-12-05T00:00:00.000Z","draft":false,"authors":["elleuch"],"tags":["STACK The Flags 2022","fullpwn","Electron","XSS","RCE","Selenium","HackTheBox"],"summary":"Fullpwn Solutions from STACK The Flags CTF","slug":"stack-the-flags-2022/fullpwn"}},"__N_SSG":true},"page":"/blog/[...slug]","query":{"slug":["gdg-algiers-2022","mlm"]},"buildId":"zs4rZRwOZcgSj8qsc8Zvy","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>